{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["pip install open3d\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xs5vZ_o87L4B","executionInfo":{"status":"ok","timestamp":1758567060876,"user_tz":-330,"elapsed":41320,"user":{"displayName":"Data4Sports","userId":"05394844190191611182"}},"outputId":"144c4551-5b66-41b9-aa19-6828f3099d31"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting open3d\n","  Downloading open3d-0.19.0-cp312-cp312-manylinux_2_31_x86_64.whl.metadata (4.3 kB)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from open3d) (2.0.2)\n","Collecting dash>=2.6.0 (from open3d)\n","  Downloading dash-3.2.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: werkzeug>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from open3d) (3.1.3)\n","Requirement already satisfied: flask>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from open3d) (3.1.2)\n","Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.12/dist-packages (from open3d) (5.10.4)\n","Collecting configargparse (from open3d)\n","  Downloading configargparse-1.7.1-py3-none-any.whl.metadata (24 kB)\n","Collecting ipywidgets>=8.0.4 (from open3d)\n","  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n","Collecting addict (from open3d)\n","  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n","Requirement already satisfied: pillow>=9.3.0 in /usr/local/lib/python3.12/dist-packages (from open3d) (11.3.0)\n","Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.12/dist-packages (from open3d) (3.10.0)\n","Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.12/dist-packages (from open3d) (2.2.2)\n","Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.12/dist-packages (from open3d) (6.0.2)\n","Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.12/dist-packages (from open3d) (1.6.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from open3d) (4.67.1)\n","Collecting pyquaternion (from open3d)\n","  Downloading pyquaternion-0.9.9-py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from dash>=2.6.0->open3d) (5.24.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/dist-packages (from dash>=2.6.0->open3d) (8.7.0)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from dash>=2.6.0->open3d) (4.15.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from dash>=2.6.0->open3d) (2.32.4)\n","Collecting retrying (from dash>=2.6.0->open3d)\n","  Downloading retrying-1.4.2-py3-none-any.whl.metadata (5.5 kB)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from dash>=2.6.0->open3d) (75.2.0)\n","Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask>=3.0.0->open3d) (1.9.0)\n","Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask>=3.0.0->open3d) (8.2.1)\n","Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask>=3.0.0->open3d) (2.2.0)\n","Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask>=3.0.0->open3d) (3.1.6)\n","Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask>=3.0.0->open3d) (3.0.2)\n","Collecting comm>=0.1.3 (from ipywidgets>=8.0.4->open3d)\n","  Downloading comm-0.2.3-py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n","Collecting widgetsnbextension~=4.0.14 (from ipywidgets>=8.0.4->open3d)\n","  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.15)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->open3d) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->open3d) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->open3d) (4.60.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->open3d) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->open3d) (25.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->open3d) (3.2.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->open3d) (2.9.0.post0)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.7.0->open3d) (2.21.2)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.7.0->open3d) (4.25.1)\n","Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.7.0->open3d) (5.8.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0->open3d) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0->open3d) (2025.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21->open3d) (1.16.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21->open3d) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21->open3d) (3.6.0)\n","Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.52)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.19.2)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2025.9.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.27.1)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.4.0)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.5.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3->open3d) (1.17.0)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.23.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->dash>=2.6.0->open3d) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->dash>=2.6.0->open3d) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->dash>=2.6.0->open3d) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->dash>=2.6.0->open3d) (2025.8.3)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.5)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n","Downloading open3d-0.19.0-cp312-cp312-manylinux_2_31_x86_64.whl (447.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.7/447.7 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dash-3.2.0-py3-none-any.whl (7.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Downloading configargparse-1.7.1-py3-none-any.whl (25 kB)\n","Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n","Downloading comm-0.2.3-py3-none-any.whl (7.3 kB)\n","Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading retrying-1.4.2-py3-none-any.whl (10 kB)\n","Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: addict, widgetsnbextension, retrying, pyquaternion, jedi, configargparse, comm, ipywidgets, dash, open3d\n","  Attempting uninstall: widgetsnbextension\n","    Found existing installation: widgetsnbextension 3.6.10\n","    Uninstalling widgetsnbextension-3.6.10:\n","      Successfully uninstalled widgetsnbextension-3.6.10\n","  Attempting uninstall: ipywidgets\n","    Found existing installation: ipywidgets 7.7.1\n","    Uninstalling ipywidgets-7.7.1:\n","      Successfully uninstalled ipywidgets-7.7.1\n","Successfully installed addict-2.4.0 comm-0.2.3 configargparse-1.7.1 dash-3.2.0 ipywidgets-8.1.7 jedi-0.19.2 open3d-0.19.0 pyquaternion-0.9.9 retrying-1.4.2 widgetsnbextension-4.0.14\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4vV-w-yW7fPw","executionInfo":{"status":"ok","timestamp":1758567173853,"user_tz":-330,"elapsed":111864,"user":{"displayName":"Data4Sports","userId":"05394844190191611182"}},"outputId":"3310d32e-d646-4d28-cfed-71d6d9a4c4b2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["#step 1 train"],"metadata":{"id":"yOZ3oGtu9N-t"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jd38x2LD55nH","executionInfo":{"status":"ok","timestamp":1758498966938,"user_tz":-330,"elapsed":5431651,"user":{"displayName":"Data4Sports","userId":"05394844190191611182"}},"outputId":"743c17e8-cb68-4c48-a33d-3bc30f1b899a"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Verifying data loading...\n","Loaded 65 samples for train\n","✅ Successfully loaded sample:\n","   CBCT shape: torch.Size([1024, 3])\n","   STL shape: torch.Size([1024, 3])\n","   Target shape: torch.Size([1024, 3])\n","   GT transform shape: torch.Size([4, 4])\n","   Case ID: 010\n","\n","============================================================\n","STARTING STSR 2025 OFFICIAL TRAINING\n","============================================================\n","Using device: cuda\n","Creating datasets...\n","Loaded 65 samples for train\n","Loaded 15 samples for val\n","Loaded 300 samples for test\n","Dataset sizes - Train: 65, Val: 15, Test: 300\n","Creating model...\n","Model parameters - Total: 813,586, Trainable: 813,586\n","\n","Starting training...\n","\n","Epoch 1/50\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 16/16 [06:22<00:00, 23.92s/it, Loss=9.2038, Chamfer=5.7069, Transform=3.4969]\n","Validation: 100%|██████████| 3/3 [00:51<00:00, 17.11s/it, Loss=8.2894, Chamfer=5.0162, Transform=3.2732]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 8.846834 | Val Loss: 10.886017\n","RMSE: 2.2452 | Translation: 55.0958mm | Rotation: 121.81°\n","Surface Dice: 0.0003 | Chamfer: 6.8200\n","✓ Best model saved: 10.886017\n","\n","Epoch 2/50\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 16/16 [06:31<00:00, 24.45s/it, Loss=8.6391, Chamfer=5.3487, Transform=3.2904]\n","Validation: 100%|██████████| 3/3 [00:54<00:00, 18.25s/it, Loss=2.9302, Chamfer=1.5762, Transform=1.3540]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 9.025635 | Val Loss: 4.717251\n","RMSE: 1.0454 | Translation: 55.4100mm | Rotation: 115.98°\n","Surface Dice: 0.4840 | Chamfer: 2.7424\n","✓ Best model saved: 4.717251\n","\n","Epoch 3/50\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 16/16 [06:24<00:00, 24.02s/it, Loss=7.9775, Chamfer=4.8970, Transform=3.0805]\n","Validation: 100%|██████████| 3/3 [00:53<00:00, 17.86s/it, Loss=4.2779, Chamfer=2.3806, Transform=1.8973]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 7.365088 | Val Loss: 6.513422\n","RMSE: 1.3645 | Translation: 55.2874mm | Rotation: 123.11°\n","Surface Dice: 0.1933 | Chamfer: 3.9013\n","No improvement for 1/10 epochs\n","\n","Epoch 4/50\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 16/16 [06:32<00:00, 24.55s/it, Loss=10.9640, Chamfer=7.0681, Transform=3.8959]\n","Validation: 100%|██████████| 3/3 [00:54<00:00, 18.21s/it, Loss=2.8043, Chamfer=1.4657, Transform=1.3386]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 7.525728 | Val Loss: 4.283135\n","RMSE: 0.9470 | Translation: 55.6400mm | Rotation: 120.43°\n","Surface Dice: 0.4942 | Chamfer: 2.4635\n","✓ Best model saved: 4.283135\n","\n","Epoch 5/50\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 16/16 [06:37<00:00, 24.85s/it, Loss=5.3800, Chamfer=3.1657, Transform=2.2143]\n","Validation: 100%|██████████| 3/3 [00:54<00:00, 18.13s/it, Loss=3.2027, Chamfer=1.7657, Transform=1.4371]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 6.338415 | Val Loss: 4.279178\n","RMSE: 0.9446 | Translation: 55.7122mm | Rotation: 123.69°\n","Surface Dice: 0.3615 | Chamfer: 2.4874\n","✓ Best model saved: 4.279178\n","\n","Epoch 6/50\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 16/16 [06:25<00:00, 24.07s/it, Loss=6.4990, Chamfer=4.0750, Transform=2.4240]\n","Validation: 100%|██████████| 3/3 [00:53<00:00, 17.78s/it, Loss=2.9025, Chamfer=1.5731, Transform=1.3294]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 6.430045 | Val Loss: 4.140275\n","RMSE: 0.9329 | Translation: 55.8639mm | Rotation: 125.79°\n","Surface Dice: 0.4492 | Chamfer: 2.4200\n","✓ Best model saved: 4.140275\n","\n","Epoch 7/50\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 16/16 [06:28<00:00, 24.29s/it, Loss=7.9711, Chamfer=5.0840, Transform=2.8871]\n","Validation: 100%|██████████| 3/3 [00:51<00:00, 17.31s/it, Loss=2.6867, Chamfer=1.4448, Transform=1.2418]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 6.725960 | Val Loss: 3.126103\n","RMSE: 0.7381 | Translation: 55.9847mm | Rotation: 122.01°\n","Surface Dice: 0.6340 | Chamfer: 1.7604\n","✓ Best model saved: 3.126103\n","\n","Epoch 8/50\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 16/16 [06:20<00:00, 23.80s/it, Loss=7.0849, Chamfer=4.3822, Transform=2.7028]\n","Validation: 100%|██████████| 3/3 [00:53<00:00, 17.94s/it, Loss=3.4076, Chamfer=1.8730, Transform=1.5346]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 6.189161 | Val Loss: 3.252779\n","RMSE: 0.7763 | Translation: 55.8468mm | Rotation: 120.79°\n","Surface Dice: 0.6076 | Chamfer: 1.8130\n","No improvement for 1/10 epochs\n","\n","Epoch 9/50\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 16/16 [07:00<00:00, 26.30s/it, Loss=9.1571, Chamfer=5.8484, Transform=3.3088]\n","Validation: 100%|██████████| 3/3 [00:58<00:00, 19.49s/it, Loss=2.9819, Chamfer=1.6990, Transform=1.2829]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 6.167633 | Val Loss: 3.735331\n","RMSE: 0.8653 | Translation: 55.5245mm | Rotation: 130.63°\n","Surface Dice: 0.3884 | Chamfer: 2.2247\n","No improvement for 2/10 epochs\n","\n","Epoch 10/50\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 16/16 [06:27<00:00, 24.20s/it, Loss=7.2824, Chamfer=4.6304, Transform=2.6519]\n","Validation: 100%|██████████| 3/3 [00:54<00:00, 18.00s/it, Loss=2.1802, Chamfer=1.1260, Transform=1.0542]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 7.178961 | Val Loss: 2.321796\n","RMSE: 0.6098 | Translation: 55.9532mm | Rotation: 134.15°\n","Surface Dice: 0.8939 | Chamfer: 1.2844\n","✓ Best model saved: 2.321796\n","\n","Epoch 11/50\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 16/16 [06:24<00:00, 24.00s/it, Loss=7.0720, Chamfer=4.3988, Transform=2.6732]\n","Validation: 100%|██████████| 3/3 [00:53<00:00, 17.82s/it, Loss=4.5535, Chamfer=2.5597, Transform=1.9938]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 5.698955 | Val Loss: 4.468041\n","RMSE: 1.0011 | Translation: 55.6411mm | Rotation: 139.83°\n","Surface Dice: 0.2379 | Chamfer: 2.5943\n","No improvement for 1/10 epochs\n","\n","Epoch 12/50\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 16/16 [06:28<00:00, 24.29s/it, Loss=5.5974, Chamfer=3.4934, Transform=2.1041]\n","Validation: 100%|██████████| 3/3 [00:52<00:00, 17.42s/it, Loss=6.1363, Chamfer=3.6533, Transform=2.4830]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 5.846851 | Val Loss: 5.640165\n","RMSE: 1.2255 | Translation: 56.0726mm | Rotation: 147.37°\n","Surface Dice: 0.0042 | Chamfer: 3.4036\n","No improvement for 2/10 epochs\n","\n","Epoch 13/50\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 16/16 [06:20<00:00, 23.77s/it, Loss=5.2247, Chamfer=3.2871, Transform=1.9375]\n","Validation: 100%|██████████| 3/3 [00:54<00:00, 18.06s/it, Loss=4.0269, Chamfer=2.2731, Transform=1.7538]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 5.379524 | Val Loss: 3.867867\n","RMSE: 0.8938 | Translation: 56.1534mm | Rotation: 148.34°\n","Surface Dice: 0.4458 | Chamfer: 2.1874\n","No improvement for 3/10 epochs\n","\n","Epoch 14/50\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 16/16 [06:27<00:00, 24.22s/it, Loss=5.0769, Chamfer=3.0910, Transform=1.9859]\n","Validation: 100%|██████████| 3/3 [00:53<00:00, 17.70s/it, Loss=3.5630, Chamfer=1.9614, Transform=1.6016]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 5.390950 | Val Loss: 3.445216\n","RMSE: 0.8191 | Translation: 56.1312mm | Rotation: 141.42°\n","Surface Dice: 0.6020 | Chamfer: 1.9198\n","No improvement for 4/10 epochs\n","\n","Epoch 15/50\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 16/16 [06:19<00:00, 23.74s/it, Loss=6.9796, Chamfer=4.3868, Transform=2.5927]\n","Validation: 100%|██████████| 3/3 [00:54<00:00, 18.16s/it, Loss=7.0128, Chamfer=4.1104, Transform=2.9024]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 5.243980 | Val Loss: 6.836601\n","RMSE: 1.4229 | Translation: 55.8779mm | Rotation: 129.51°\n","Surface Dice: 0.0000 | Chamfer: 4.0631\n","No improvement for 5/10 epochs\n","\n","Epoch 16/50\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 16/16 [06:25<00:00, 24.12s/it, Loss=4.4663, Chamfer=2.6064, Transform=1.8599]\n","Validation: 100%|██████████| 3/3 [00:52<00:00, 17.52s/it, Loss=4.9028, Chamfer=2.8508, Transform=2.0520]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 5.616049 | Val Loss: 6.286668\n","RMSE: 1.3095 | Translation: 56.2062mm | Rotation: 145.10°\n","Surface Dice: 0.0827 | Chamfer: 3.7357\n","No improvement for 6/10 epochs\n","\n","Epoch 17/50\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 16/16 [06:26<00:00, 24.17s/it, Loss=3.2060, Chamfer=1.6709, Transform=1.5352]\n","Validation: 100%|██████████| 3/3 [00:53<00:00, 17.68s/it, Loss=4.5900, Chamfer=2.7069, Transform=1.8831]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 5.574889 | Val Loss: 5.973901\n","RMSE: 1.2546 | Translation: 56.2413mm | Rotation: 149.91°\n","Surface Dice: 0.1146 | Chamfer: 3.5874\n","No improvement for 7/10 epochs\n","\n","Epoch 18/50\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 16/16 [06:23<00:00, 23.99s/it, Loss=3.0795, Chamfer=1.9409, Transform=1.1386]\n","Validation: 100%|██████████| 3/3 [00:54<00:00, 18.06s/it, Loss=7.9501, Chamfer=4.8650, Transform=3.0852]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 5.854249 | Val Loss: 9.949487\n","RMSE: 2.0126 | Translation: 56.7880mm | Rotation: 146.49°\n","Surface Dice: 0.0279 | Chamfer: 6.1733\n","No improvement for 8/10 epochs\n","\n","Epoch 19/50\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 16/16 [06:18<00:00, 23.69s/it, Loss=7.7197, Chamfer=4.7073, Transform=3.0123]\n","Validation: 100%|██████████| 3/3 [00:52<00:00, 17.46s/it, Loss=3.8756, Chamfer=2.2633, Transform=1.6123]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 5.385861 | Val Loss: 4.622638\n","RMSE: 1.0074 | Translation: 56.4190mm | Rotation: 129.47°\n","Surface Dice: 0.3430 | Chamfer: 2.7221\n","No improvement for 9/10 epochs\n","\n","Epoch 20/50\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 16/16 [06:24<00:00, 24.06s/it, Loss=4.5070, Chamfer=2.7269, Transform=1.7802]\n","Validation: 100%|██████████| 3/3 [00:53<00:00, 17.76s/it, Loss=3.4447, Chamfer=1.9634, Transform=1.4813]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 5.279213 | Val Loss: 5.116533\n","RMSE: 1.0966 | Translation: 56.2708mm | Rotation: 148.77°\n","Surface Dice: 0.3699 | Chamfer: 3.0275\n","No improvement for 10/10 epochs\n","Early stopping triggered after 20 epochs\n","✓ Final model saved\n","✓ Training curves saved to: /content/drive/MyDrive/Papers/STS_2025/VERSION2/RESULTS_OFFICIAL/training_curves_complete.png\n","\n","Loading best model for inference...\n","✓ Model loaded successfully\n","\n","Final evaluation on validation set:\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 3/3 [00:52<00:00, 17.54s/it, Loss=2.2334, Chamfer=1.1573, Transform=1.0760]"]},{"output_type":"stream","name":"stdout","text":["\n","Final Results:\n","Validation Loss: 2.327959\n","RMSE: 0.6107 mm\n","NCC: 0.0552\n","NMI: 0.1176\n","Surface Dice: 0.8891\n","Chamfer Distance: 1.2895\n","Translation Error: 55.9565 mm\n","Rotation Error: 134.07 degrees\n","\n","All results saved to: /content/drive/MyDrive/Papers/STS_2025/VERSION2/RESULTS_OFFICIAL\n","Training completed successfully!\n","\n","============================================================\n","TRAINING COMPLETED SUCCESSFULLY!\n","============================================================\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["\"\"\"\n","Complete STSR 2025 Challenge Implementation\n","Following official GitHub structure with proper data processing,\n","correct model architecture, and evaluation metrics.\n","\"\"\"\n","\n","import os\n","import gc\n","import time\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import open3d as o3d\n","from pathlib import Path\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from scipy.spatial.distance import cdist\n","from scipy.spatial.transform import Rotation\n","import nibabel as nib\n","import json\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# ============================================================================\n","# OFFICIAL STSR DATA PROCESSING (from GitHub)\n","# ============================================================================\n","\n","def compute_aabb(points):\n","    \"\"\"Compute axis-aligned bounding box\"\"\"\n","    min_coords = np.min(points, axis=0)\n","    max_coords = np.max(points, axis=0)\n","    center = (min_coords + max_coords) / 2\n","    return min_coords, max_coords, center\n","\n","def center_align_points(points, center):\n","    \"\"\"Center align points to given center\"\"\"\n","    return points - center\n","\n","class RandomRigidTransform:\n","    \"\"\"Official data augmentation from GitHub\"\"\"\n","    def __init__(self, mag_trans=0.5, mag_rot=45):\n","        self.mag_trans = mag_trans  # Translation magnitude in meters\n","        self.mag_rot = mag_rot      # Rotation magnitude in degrees\n","\n","    def __call__(self, points):\n","        # Random rotation\n","        angle_x = np.random.uniform(-self.mag_rot, self.mag_rot)\n","        angle_y = np.random.uniform(-self.mag_rot, self.mag_rot)\n","        angle_z = np.random.uniform(-self.mag_rot, self.mag_rot)\n","        rotation = Rotation.from_euler('xyz', [angle_x, angle_y, angle_z], degrees=True)\n","        R = rotation.as_matrix()\n","\n","        # Random translation\n","        t = np.random.uniform(-self.mag_trans, self.mag_trans, size=3)\n","\n","        # Build 4x4 transformation matrix\n","        transform = np.identity(4)\n","        transform[:3, :3] = R\n","        transform[:3, 3] = t\n","\n","        # Apply transformation\n","        points_homogeneous = np.hstack([points, np.ones((points.shape[0], 1))])\n","        transformed_points = (transform @ points_homogeneous.T).T[:, :3]\n","\n","        return transformed_points, transform\n","\n","# ============================================================================\n","# OFFICIAL EVALUATION METRICS (from GitHub)\n","# ============================================================================\n","\n","def compute_rmse(pred_points, gt_points):\n","    \"\"\"Root Mean Square Error\"\"\"\n","    return np.sqrt(np.mean((pred_points - gt_points) ** 2))\n","\n","def compute_ncc(pred_points, gt_points):\n","    \"\"\"Normalized Cross-Correlation\"\"\"\n","    pred_flat = pred_points.flatten()\n","    gt_flat = gt_points.flatten()\n","\n","    pred_centered = pred_flat - np.mean(pred_flat)\n","    gt_centered = gt_flat - np.mean(gt_flat)\n","\n","    numerator = np.sum(pred_centered * gt_centered)\n","    denominator = np.sqrt(np.sum(pred_centered**2) * np.sum(gt_centered**2))\n","\n","    return numerator / (denominator + 1e-8)\n","\n","def compute_nmi(pred_points, gt_points, bins=50):\n","    \"\"\"Normalized Mutual Information\"\"\"\n","    from sklearn.metrics import normalized_mutual_info_score\n","\n","    pred_flat = pred_points.flatten()\n","    gt_flat = gt_points.flatten()\n","\n","    # Normalize to [0, 1]\n","    pred_norm = (pred_flat - pred_flat.min()) / (pred_flat.max() - pred_flat.min() + 1e-8)\n","    gt_norm = (gt_flat - gt_flat.min()) / (gt_flat.max() - gt_flat.min() + 1e-8)\n","\n","    # Discretize\n","    pred_discrete = np.floor(pred_norm * (bins - 1)).astype(int)\n","    gt_discrete = np.floor(gt_norm * (bins - 1)).astype(int)\n","\n","    return normalized_mutual_info_score(pred_discrete, gt_discrete)\n","\n","def surface_dice(pred_points, gt_points, tolerance=1.0):\n","    \"\"\"Surface Dice coefficient (from SurfaceDice.py)\"\"\"\n","    # Find correspondences within tolerance\n","    distances = cdist(pred_points, gt_points)\n","\n","    # Points in pred that are close to gt\n","    pred_close = np.any(distances <= tolerance, axis=1)\n","\n","    # Points in gt that are close to pred\n","    gt_close = np.any(distances <= tolerance, axis=0)\n","\n","    intersection = np.sum(pred_close) + np.sum(gt_close)\n","    union = len(pred_points) + len(gt_points)\n","\n","    return intersection / union if union > 0 else 0.0\n","class STSRDataset(Dataset):\n","    \"\"\"STSR dataset following official structure\"\"\"\n","\n","    def __init__(self, root_dir, n_points=2048, mode='train', augment=True):\n","        self.root_dir = Path(root_dir)\n","        self.n_points = n_points\n","        self.mode = mode\n","        self.augment = augment\n","\n","        # Load data pairs\n","        self.samples = self._load_samples()\n","\n","        # Data augmentation\n","        if augment:\n","            self.transform = RandomRigidTransform(mag_trans=0.1, mag_rot=15)\n","        else:\n","            self.transform = None\n","\n","    def _load_samples(self):\n","        samples = []\n","\n","        if self.mode == 'train':\n","            images_dir = self.root_dir / \"Initial_Train_65\" / \"Images\"\n","            labels_dir = self.root_dir / \"Initial_Train_65\" / \"Labels\"\n","        elif self.mode == 'val':\n","            images_dir = self.root_dir / \"Final_Validation_15\" / \"Images\"\n","            labels_dir = self.root_dir / \"Final_Validation_15\" / \"Labels\"\n","        else:  # test\n","            images_dir = self.root_dir / \"Unlabeled_300\" / \"Images\"\n","            labels_dir = None\n","\n","        if not images_dir.exists():\n","            print(f\"Warning: {images_dir} does not exist\")\n","            return samples\n","\n","        for case_dir in images_dir.iterdir():\n","            if case_dir.is_dir():\n","                case_id = case_dir.name\n","\n","                cbct_path = case_dir / \"CBCT.nii.gz\"\n","                upper_stl = case_dir / \"upper.stl\"\n","                lower_stl = case_dir / \"lower.stl\"\n","\n","                if not cbct_path.exists():\n","                    print(f\"Warning: CBCT file not found for case {case_id}\")\n","                    continue\n","\n","                sample = {\n","                    'case_id': case_id,\n","                    'cbct_path': cbct_path,\n","                    'upper_stl_path': upper_stl if upper_stl.exists() else None,\n","                    'lower_stl_path': lower_stl if lower_stl.exists() else None,\n","                }\n","\n","                # Add ground truth if available\n","                if labels_dir and (labels_dir / case_id).exists():\n","                    upper_gt = labels_dir / case_id / \"upper_gt.npy\"\n","                    lower_gt = labels_dir / case_id / \"lower_gt.npy\"\n","\n","                    if upper_gt.exists():\n","                        sample['upper_gt_path'] = upper_gt\n","                    if lower_gt.exists():\n","                        sample['lower_gt_path'] = lower_gt\n","\n","                samples.append(sample)\n","\n","        print(f\"Loaded {len(samples)} samples for {self.mode}\")\n","        return samples\n","\n","    def extract_cbct_points(self, cbct_path, threshold=800, max_points=50000):\n","        \"\"\"FIXED: Use 800 HU threshold as per GitHub dataset.py\"\"\"\n","        try:\n","            if not cbct_path.exists():\n","                print(f\"Warning: CBCT file does not exist: {cbct_path}\")\n","                return np.zeros((1000, 3), dtype=np.float32)\n","\n","            cbct_img = nib.load(str(cbct_path))\n","            cbct_data = cbct_img.get_fdata()\n","\n","            # FIXED: 800 HU threshold (was 500)\n","            points_voxel = np.argwhere(cbct_data > threshold)\n","\n","            if len(points_voxel) == 0:\n","                return np.zeros((1000, 3), dtype=np.float32)\n","\n","            # Convert to world coordinates\n","            points_h = np.hstack([points_voxel[:, [2, 1, 0]], np.ones((points_voxel.shape[0], 1))])\n","            points_world = (cbct_img.affine @ points_h.T).T[:, :3]\n","\n","            # FIXED: Proper subsampling\n","            if len(points_world) > max_points:\n","                indices = np.random.choice(len(points_world), max_points, replace=False)\n","                points_world = points_world[indices]\n","\n","            return points_world.astype(np.float32)\n","\n","        except Exception as e:\n","            print(f\"Error extracting CBCT: {e}\")\n","            return np.zeros((1000, 3), dtype=np.float32)\n","    def extract_stl_points(self, stl_path, max_points=50000):\n","        \"\"\"Extract points from STL mesh\"\"\"\n","        try:\n","            if stl_path is None or not stl_path.exists():\n","                return np.zeros((1000, 3), dtype=np.float32)\n","\n","            mesh = o3d.io.read_triangle_mesh(str(stl_path))\n","\n","            if len(mesh.triangles) == 0 or len(mesh.vertices) == 0:\n","                return np.zeros((1000, 3), dtype=np.float32)\n","\n","            # Use vertices directly (official approach)\n","            points = np.asarray(mesh.vertices)\n","\n","            # Subsample if too many points\n","            if len(points) > max_points:\n","                indices = np.random.choice(len(points), max_points, replace=False)\n","                points = points[indices]\n","\n","            return points.astype(np.float32)\n","\n","        except Exception as e:\n","            print(f\"Error extracting STL: {e}\")\n","            return np.zeros((1000, 3), dtype=np.float32)\n","\n","    def sample_points(self, points, n_target):\n","        \"\"\"Sample points to target number\"\"\"\n","        if len(points) == 0:\n","            return np.zeros((n_target, 3), dtype=np.float32)\n","\n","        if len(points) >= n_target:\n","            indices = np.random.choice(len(points), n_target, replace=False)\n","            return points[indices]\n","        else:\n","            indices = np.random.choice(len(points), n_target, replace=True)\n","            return points[indices]\n","\n","    def __getitem__(self, idx):\n","        \"\"\"FIXED: Proper normalization instead of center alignment\"\"\"\n","        sample = self.samples[idx]\n","\n","        # Extract with official parameters\n","        cbct_points = self.extract_cbct_points(sample['cbct_path'], threshold=800, max_points=50000)\n","        upper_points = self.extract_stl_points(sample['upper_stl_path'], max_points=50000)\n","        lower_points = self.extract_stl_points(sample['lower_stl_path'], max_points=50000)\n","\n","        # Combine STL points\n","        if len(upper_points) > 0 and len(lower_points) > 0:\n","            stl_points = np.vstack([upper_points, lower_points])\n","        elif len(upper_points) > 0:\n","            stl_points = upper_points\n","        elif len(lower_points) > 0:\n","            stl_points = lower_points\n","        else:\n","            stl_points = np.zeros((1000, 3), dtype=np.float32)\n","\n","        # Apply ground truth transformation\n","        target_points = stl_points.copy()\n","        gt_transform = np.eye(4, dtype=np.float32)\n","\n","        # Safe ground truth loading\n","        upper_gt_exists = ('upper_gt_path' in sample and\n","                          sample['upper_gt_path'] is not None and\n","                          sample['upper_gt_path'].exists())\n","\n","        if upper_gt_exists and len(upper_points) > 0:\n","            try:\n","                upper_gt = np.load(sample['upper_gt_path'])\n","                upper_h = np.hstack([upper_points, np.ones((len(upper_points), 1))])\n","                upper_transformed = (upper_gt @ upper_h.T).T[:, :3]\n","\n","                lower_gt_exists = ('lower_gt_path' in sample and\n","                                  sample['lower_gt_path'] is not None and\n","                                  sample['lower_gt_path'].exists())\n","\n","                if lower_gt_exists and len(lower_points) > 0:\n","                    try:\n","                        lower_gt = np.load(sample['lower_gt_path'])\n","                        lower_h = np.hstack([lower_points, np.ones((len(lower_points), 1))])\n","                        lower_transformed = (lower_gt @ lower_h.T).T[:, :3]\n","                        target_points = np.vstack([upper_transformed, lower_transformed])\n","                    except:\n","                        target_points = upper_transformed\n","                else:\n","                    target_points = upper_transformed\n","\n","                gt_transform = upper_gt\n","\n","            except Exception as e:\n","                print(f\"Error loading GT for {sample['case_id']}: {e}\")\n","\n","        # FIXED: Proper normalization following GitHub transforms.py\n","        if len(cbct_points) > 0 and len(stl_points) > 0:\n","            # Global normalization (following GitHub)\n","            all_points = np.vstack([cbct_points, stl_points])\n","            center = np.mean(all_points, axis=0)\n","            scale = np.max(np.linalg.norm(all_points - center, axis=1))\n","\n","            if scale > 0:\n","                cbct_norm = (cbct_points - center) / scale\n","                stl_norm = (stl_points - center) / scale\n","                target_norm = (target_points - center) / scale\n","            else:\n","                cbct_norm = cbct_points - center\n","                stl_norm = stl_points - center\n","                target_norm = target_points - center\n","            norm_center = torch.from_numpy(center).float()\n","            norm_scale = torch.tensor(scale).float()\n","        else:\n","            cbct_norm = cbct_points\n","            stl_norm = stl_points\n","            target_norm = target_points\n","            norm_center = torch.zeros(3).float()\n","            norm_scale = torch.tensor(1.0).float()\n","\n","        # Apply data augmentation if enabled\n","        if self.transform is not None and self.mode == 'train':\n","            stl_norm, aug_transform = self.transform(stl_norm)\n","            gt_transform = aug_transform @ gt_transform\n","\n","        # Sample to target size\n","        cbct_sampled = self.sample_points(cbct_norm, self.n_points)\n","        stl_sampled = self.sample_points(stl_norm, self.n_points)\n","        target_sampled = self.sample_points(target_norm, self.n_points)\n","\n","        return {\n","              'cbct': torch.from_numpy(cbct_sampled).float(),\n","              'stl': torch.from_numpy(stl_sampled).float(),\n","              'target': torch.from_numpy(target_sampled).float(),\n","              'gt_transform': torch.from_numpy(gt_transform).float(),\n","              'norm_center': norm_center,  # ADD THIS\n","              'norm_scale': norm_scale,    # ADD THIS\n","              'case_id': sample['case_id']\n","          }\n","\n","    def __len__(self):\n","        return len(self.samples)\n","class STSROfficialEvaluator:\n","    \"\"\"Official STSR evaluation metrics\"\"\"\n","\n","    def __init__(self):\n","        self.metrics = {}\n","\n","    def evaluate_registration(self, pred_stl, gt_stl, pred_transform=None, gt_transform=None):\n","        \"\"\"Complete evaluation with all official metrics\"\"\"\n","        metrics = {}\n","\n","        try:\n","            # Convert tensors if needed\n","            if torch.is_tensor(pred_stl):\n","                pred_stl = pred_stl.detach().cpu().numpy()\n","            if torch.is_tensor(gt_stl):\n","                gt_stl = gt_stl.detach().cpu().numpy()\n","\n","            # Handle batch dimension\n","            if len(pred_stl.shape) == 3:\n","                pred_stl = pred_stl.reshape(-1, 3)\n","            if len(gt_stl.shape) == 3:\n","                gt_stl = gt_stl.reshape(-1, 3)\n","\n","            # Check for valid data\n","            if len(pred_stl) == 0 or len(gt_stl) == 0:\n","                return self._default_metrics()\n","\n","            # Official metrics with error handling\n","            try:\n","                metrics['rmse'] = float(compute_rmse(pred_stl, gt_stl))\n","            except:\n","                metrics['rmse'] = 0.0\n","\n","            try:\n","                metrics['ncc'] = float(compute_ncc(pred_stl, gt_stl))\n","            except:\n","                metrics['ncc'] = 0.0\n","\n","            try:\n","                metrics['nmi'] = float(compute_nmi(pred_stl, gt_stl))\n","            except:\n","                metrics['nmi'] = 0.0\n","\n","            try:\n","                metrics['surface_dice'] = float(surface_dice(pred_stl, gt_stl))\n","            except:\n","                metrics['surface_dice'] = 0.0\n","\n","            # Chamfer distance\n","            try:\n","                dist1 = np.min(cdist(pred_stl, gt_stl), axis=1)\n","                dist2 = np.min(cdist(gt_stl, pred_stl), axis=1)\n","                metrics['chamfer_distance'] = float(np.mean(dist1) + np.mean(dist2))\n","            except:\n","                metrics['chamfer_distance'] = 0.0\n","\n","            # Transformation metrics with robust error handling\n","            if pred_transform is not None and gt_transform is not None:\n","                try:\n","                    # Convert to numpy\n","                    if torch.is_tensor(pred_transform):\n","                        pred_transform = pred_transform.detach().cpu().numpy()\n","                    if torch.is_tensor(gt_transform):\n","                        gt_transform = gt_transform.detach().cpu().numpy()\n","\n","                    # Handle different input shapes\n","                    if len(pred_transform.shape) == 3:  # Batch dimension\n","                        pred_T = pred_transform[0]\n","                        gt_T = gt_transform[0]\n","                    else:  # Single matrix\n","                        pred_T = pred_transform\n","                        gt_T = gt_transform\n","\n","                    # Ensure 4x4 matrices\n","                    if pred_T.shape == (4, 4) and gt_T.shape == (4, 4):\n","                        # Translation error\n","                        pred_trans = pred_T[:3, 3]\n","                        gt_trans = gt_T[:3, 3]\n","                        metrics['translation_error'] = float(np.linalg.norm(pred_trans - gt_trans))\n","\n","                        # Rotation error\n","                        pred_rot = pred_T[:3, :3]\n","                        gt_rot = gt_T[:3, :3]\n","\n","                        # Ensure valid rotation matrices\n","                        if (np.allclose(np.linalg.det(pred_rot), 1, atol=0.1) and\n","                            np.allclose(np.linalg.det(gt_rot), 1, atol=0.1)):\n","\n","                            rot_diff = pred_rot @ gt_rot.T\n","                            trace = np.trace(rot_diff)\n","\n","                            # Clamp trace for numerical stability\n","                            trace = np.clip(trace, -1, 3)\n","                            angle = np.arccos(np.clip((trace - 1) / 2, -1, 1))\n","                            metrics['rotation_error_degrees'] = float(np.degrees(angle))\n","                        else:\n","                            metrics['rotation_error_degrees'] = 0.0\n","                    else:\n","                        metrics['translation_error'] = 0.0\n","                        metrics['rotation_error_degrees'] = 0.0\n","\n","                except Exception as e:\n","                    print(f\"Warning: Transform metrics failed: {e}\")\n","                    metrics['translation_error'] = 0.0\n","                    metrics['rotation_error_degrees'] = 0.0\n","            else:\n","                metrics['translation_error'] = 0.0\n","                metrics['rotation_error_degrees'] = 0.0\n","\n","        except Exception as e:\n","            print(f\"Warning: Evaluation failed: {e}\")\n","            return self._default_metrics()\n","\n","        return metrics\n","\n","    def _default_metrics(self):\n","        \"\"\"Return default metrics when evaluation fails\"\"\"\n","        return {\n","            'rmse': 0.0,\n","            'ncc': 0.0,\n","            'nmi': 0.0,\n","            'surface_dice': 0.0,\n","            'chamfer_distance': 0.0,\n","            'translation_error': 0.0,\n","            'rotation_error_degrees': 0.0\n","        }\n","\n","\n","\n","class PointNetFeatureExtractor(nn.Module):\n","    \"\"\"PointNet feature extractor for point clouds\"\"\"\n","\n","    def __init__(self, input_dim=3, feature_dim=1024):\n","        super().__init__()\n","\n","        self.conv1 = nn.Conv1d(input_dim, 64, 1)\n","        self.conv2 = nn.Conv1d(64, 128, 1)\n","        self.conv3 = nn.Conv1d(128, feature_dim, 1)\n","\n","        self.bn1 = nn.BatchNorm1d(64)\n","        self.bn2 = nn.BatchNorm1d(128)\n","        self.bn3 = nn.BatchNorm1d(feature_dim)\n","\n","        self.dropout = nn.Dropout(0.3)\n","\n","    def forward(self, x):\n","        # x: [B, N, 3] -> [B, 3, N]\n","        x = x.transpose(2, 1)\n","\n","        x = torch.relu(self.bn1(self.conv1(x)))\n","        x = torch.relu(self.bn2(self.conv2(x)))\n","        x = self.bn3(self.conv3(x))\n","\n","        # Global max pooling\n","        x = torch.max(x, 2, keepdim=True)[0]\n","        x = x.view(-1, x.size(1))\n","\n","        return self.dropout(x)\n","\n","class PointNetLK(nn.Module):\n","    \"\"\"PointNetLK registration model\"\"\"\n","\n","    def __init__(self, feature_extractor, num_iterations=10, feature_dim=1024):\n","        super().__init__()\n","        self.feature_extractor = feature_extractor\n","        self.num_iterations = num_iterations\n","\n","        # THIS WAS MISSING - Add the update network\n","        self.update_net = nn.Sequential(\n","            nn.Linear(feature_dim, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(512, 256),\n","            nn.BatchNorm1d(256),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(256, 6)  # 6-DOF transformation parameters\n","        )\n","\n","    def forward(self, source, target):\n","        B = source.shape[0]\n","        device = source.device\n","\n","        # Initialize transformation as identity\n","        T = torch.eye(4, device=device, dtype=source.dtype).unsqueeze(0).repeat(B, 1, 1)\n","\n","        # Extract target features ONCE (template)\n","        f_t = self.feature_extractor(target)\n","\n","        for i in range(self.num_iterations):\n","            # Apply current transformation to source\n","            source_transformed = self.apply_transform(source, T)\n","\n","            # Extract features from transformed source\n","            f_s = self.feature_extractor(source_transformed)\n","\n","            # Compute feature DIFFERENCE (Lucas-Kanade approach)\n","            feature_diff = f_t - f_s  # This is the error signal\n","\n","            # Predict incremental update\n","            update_params = self.update_net(feature_diff)\n","\n","            # Convert to transformation matrix\n","            delta_T = self.params_to_transform(update_params)\n","\n","            # Update transformation\n","            T = torch.bmm(delta_T, T)\n","\n","        return T\n","\n","    def apply_transform(self, points, T):\n","        \"\"\"Apply transformation matrix to points\"\"\"\n","        B, N, _ = points.shape\n","        ones = torch.ones(B, N, 1, device=points.device, dtype=points.dtype)\n","        points_h = torch.cat([points, ones], dim=2)\n","        transformed = torch.bmm(T, points_h.transpose(1, 2)).transpose(1, 2)\n","        return transformed[:, :, :3]\n","\n","    def params_to_transform(self, params):\n","        \"\"\"Convert 6-DOF parameters to 4x4 transformation matrix\"\"\"\n","        B = params.shape[0]\n","        device = params.device\n","\n","        # Split into translation and rotation parameters\n","        translation = params[:, :3]\n","        rotation_params = params[:, 3:]\n","\n","        # Convert rotation parameters to rotation matrix\n","        angle = torch.norm(rotation_params, dim=1, keepdim=True)\n","        axis = rotation_params / (angle + 1e-8)\n","\n","        # Rodrigues' rotation formula\n","        K = torch.zeros(B, 3, 3, device=device)\n","        K[:, 0, 1] = -axis[:, 2]\n","        K[:, 0, 2] = axis[:, 1]\n","        K[:, 1, 0] = axis[:, 2]\n","        K[:, 1, 2] = -axis[:, 0]\n","        K[:, 2, 0] = -axis[:, 1]\n","        K[:, 2, 1] = axis[:, 0]\n","\n","        I = torch.eye(3, device=device).unsqueeze(0).repeat(B, 1, 1)\n","        R = I + torch.sin(angle).unsqueeze(-1) * K + (1 - torch.cos(angle).unsqueeze(-1)) * torch.bmm(K, K)\n","\n","        # Build 4x4 transformation matrix\n","        T = torch.eye(4, device=device).unsqueeze(0).repeat(B, 1, 1)\n","        T[:, :3, :3] = R\n","        T[:, :3, 3] = translation\n","\n","        return T\n","\n","# ADD this to STSRModel:\n","class STSRModel(nn.Module):\n","    def __init__(self, feature_dim=1024, num_iterations=10):\n","        super().__init__()\n","\n","        self.feature_extractor = PointNetFeatureExtractor(3, feature_dim)\n","        self.pointnetlk = PointNetLK(self.feature_extractor, num_iterations, feature_dim)\n","\n","        # ADD: Separate heads for upper/lower if needed\n","        self.upper_head = nn.Linear(feature_dim, 6)\n","        self.lower_head = nn.Linear(feature_dim, 6)\n","\n","    def forward(self, cbct, stl, jaw_type=None):\n","        if jaw_type is not None:\n","            # Handle upper/lower separately\n","            pass\n","        else:\n","            # Current combined approach\n","            return self.pointnetlk(stl, cbct)  # FIXED: swapped order\n","\n","\n","\n","\n","# ============================================================================\n","# TRAINING PIPELINE\n","# ============================================================================\n","\n","class STSRTrainer:\n","    def __init__(self, model, device, save_dir):\n","        self.model = model\n","        self.device = device\n","        self.save_dir = Path(save_dir)\n","        self.save_dir.mkdir(parents=True, exist_ok=True)\n","\n","        self.evaluator = STSROfficialEvaluator()\n","        self.history = {\n","              'train_loss': [], 'val_loss': [],\n","              'train_chamfer': [], 'val_chamfer': [],  # Add these\n","              'train_transform': [], 'val_transform': [],  # Add these\n","              'rmse': [], 'ncc': [], 'nmi': [], 'surface_dice': [],\n","              'chamfer_distance': [],\n","              'translation_error': [],\n","              'rotation_error_degrees': [],\n","              'mean_translation_error_mm': [],\n","              'mean_rotation_error_deg': []\n","          }\n","\n","    def chamfer_loss(self, pred, target):\n","        \"\"\"Chamfer distance loss\"\"\"\n","        # pred, target: [B, N, 3]\n","        dist1 = torch.cdist(pred, target)  # [B, N, N]\n","        dist2 = torch.cdist(target, pred)  # [B, N, N]\n","\n","        cd1 = torch.mean(torch.min(dist1, dim=2)[0], dim=1)  # [B]\n","        cd2 = torch.mean(torch.min(dist2, dim=2)[0], dim=1)  # [B]\n","\n","        return torch.mean(cd1 + cd2)\n","    def normalize_gt_transform(self, gt_transform, center, scale):\n","        \"\"\"Transform GT matrix from raw coordinates to normalized space\"\"\"\n","        # gt_transform: [B, 4, 4] - transforms from raw STL to raw target\n","        # We need: normalized STL to normalized target\n","\n","        B = gt_transform.shape[0]\n","        device = gt_transform.device\n","\n","        # Create normalization matrices\n","        # S = scale matrix, T = translation matrix\n","        S_inv = torch.eye(4, device=device).unsqueeze(0).repeat(B, 1, 1)\n","        S_inv[:, :3, :3] = torch.eye(3, device=device) / scale.unsqueeze(-1).unsqueeze(-1)\n","        S_inv[:, :3, 3] = -center / scale.unsqueeze(-1)\n","\n","        S = torch.eye(4, device=device).unsqueeze(0).repeat(B, 1, 1)\n","        S[:, :3, :3] = torch.eye(3, device=device) * scale.unsqueeze(-1).unsqueeze(-1)\n","        S[:, :3, 3] = center\n","\n","        # Transform: normalized = S_inv * raw * S\n","        normalized_gt = torch.bmm(torch.bmm(S_inv, gt_transform), S)\n","\n","        return normalized_gt\n","    def combined_loss(self, predicted_stl, target_stl, pred_transform, gt_transform, norm_center, norm_scale):\n","        \"\"\"Combined loss with normalized GT transforms\"\"\"\n","\n","        # Normalize GT transform to match predicted transform coordinate system\n","        gt_transform_norm = self.normalize_gt_transform(gt_transform, norm_center, norm_scale)\n","\n","        # Chamfer loss (point alignment)\n","        chamfer = self.chamfer_loss(predicted_stl, target_stl)\n","\n","        # Transform loss (direct supervision in normalized space)\n","        trans_error = torch.mean(torch.norm(\n","            pred_transform[:, :3, 3] - gt_transform_norm[:, :3, 3], dim=1\n","        ))\n","\n","        rot_error = torch.mean(torch.norm(\n","            pred_transform[:, :3, :3] - gt_transform_norm[:, :3, :3], dim=(1,2)\n","        ))\n","\n","        transform_loss = trans_error + rot_error * 0.1\n","\n","        total_loss = chamfer + transform_loss\n","        return total_loss, chamfer, transform_loss\n","    def train_epoch(self, train_loader, optimizer):\n","        self.model.train()\n","        total_loss = 0\n","        num_batches = 0\n","\n","        pbar = tqdm(train_loader, desc=\"Training\")\n","        for batch in pbar:\n","            cbct = batch['cbct'].to(self.device)\n","            stl = batch['stl'].to(self.device)\n","            target = batch['target'].to(self.device)\n","            gt_transform = batch['gt_transform'].to(self.device)  # ADD THIS LINE\n","            norm_center = batch['norm_center'].to(self.device)    # ADD THIS LINE\n","            norm_scale = batch['norm_scale'].to(self.device)      # ADD THIS LINE\n","\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            predicted_transform = self.model(cbct, stl)\n","\n","            # Apply predicted transformation\n","            stl_h = torch.cat([stl, torch.ones(stl.shape[0], stl.shape[1], 1, device=self.device)], dim=2)\n","            predicted_stl = torch.bmm(predicted_transform, stl_h.transpose(1, 2)).transpose(1, 2)[:, :, :3]\n","\n","            # Compute combined loss\n","            total_loss_val, chamfer_loss_val, transform_loss_val = self.combined_loss(\n","                predicted_stl, target, predicted_transform, gt_transform, norm_center, norm_scale\n","            )\n","\n","            total_loss_val.backward()\n","            optimizer.step()\n","\n","            total_loss += total_loss_val.item()\n","            num_batches += 1\n","\n","            pbar.set_postfix({\n","                'Loss': f\"{total_loss_val.item():.4f}\",\n","                'Chamfer': f\"{chamfer_loss_val.item():.4f}\",\n","                'Transform': f\"{transform_loss_val.item():.4f}\"\n","            })\n","\n","        return total_loss / num_batches\n","    def validate_epoch(self, val_loader):\n","        self.model.eval()\n","        total_loss = 0\n","        all_metrics = []\n","\n","        with torch.no_grad():\n","            pbar = tqdm(val_loader, desc=\"Validation\")\n","            for batch in pbar:\n","                cbct = batch['cbct'].to(self.device)\n","                stl = batch['stl'].to(self.device)\n","                target = batch['target'].to(self.device)\n","                gt_transform = batch['gt_transform'].to(self.device)   # MOVED TO GPU\n","                norm_center = batch['norm_center'].to(self.device)    # ADD THIS LINE\n","                norm_scale = batch['norm_scale'].to(self.device)      # ADD THIS LINE\n","                # Forward pass\n","                predicted_transform = self.model(stl, cbct)\n","\n","                # Apply predicted transformation\n","                stl_h = torch.cat([stl, torch.ones(stl.shape[0], stl.shape[1], 1, device=self.device)], dim=2)\n","                predicted_stl = torch.bmm(predicted_transform, stl_h.transpose(1, 2)).transpose(1, 2)[:, :, :3]\n","\n","                # Compute loss\n","                total_loss_val, chamfer_loss_val, transform_loss_val = self.combined_loss(\n","                  predicted_stl, target, predicted_transform, gt_transform, norm_center, norm_scale\n","                  )\n","                total_loss += total_loss_val.item()\n","\n","                # Compute official metrics for each sample in batch\n","                for i in range(predicted_stl.shape[0]):\n","                    metrics = self.evaluator.evaluate_registration(\n","                        predicted_stl[i], target[i],\n","                        predicted_transform[i], gt_transform[i]  # PASS TRANSFORMS\n","                    )\n","                    all_metrics.append(metrics)\n","\n","                pbar.set_postfix({\n","                    'Loss': f\"{total_loss_val.item():.4f}\",\n","                    'Chamfer': f\"{chamfer_loss_val.item():.4f}\",\n","                    'Transform': f\"{transform_loss_val.item():.4f}\"\n","                })\n","\n","        # Average metrics\n","        avg_metrics = {}\n","        for key in all_metrics[0].keys():\n","            values = [m[key] for m in all_metrics if m[key] is not None]\n","            avg_metrics[key] = np.mean(values) if values else 0.0\n","\n","        # Add mean metrics for STSR evaluation\n","        avg_metrics['mean_translation_error_mm'] = avg_metrics.get('translation_error', 0.0)\n","        avg_metrics['mean_rotation_error_deg'] = avg_metrics.get('rotation_error_degrees', 0.0)\n","\n","        return total_loss / len(val_loader), avg_metrics\n","\n","    def train(self, train_loader, val_loader, num_epochs, lr=1e-4):\n","        optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=1e-4)\n","        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n","\n","        best_loss = float('inf')\n","        patience = 10           # EARLY STOPPING: wait 10 epochs\n","        patience_counter = 0    # EARLY STOPPING: counter\n","\n","        for epoch in range(num_epochs):\n","            print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n","\n","            # Train\n","            train_loss = self.train_epoch(train_loader, optimizer)\n","\n","            # Validate\n","            val_loss, val_metrics = self.validate_epoch(val_loader)\n","\n","            # Update scheduler\n","            scheduler.step(val_loss)\n","\n","            # Store history safely\n","            self.history['train_loss'].append(train_loss)\n","            self.history['val_loss'].append(val_loss)\n","\n","            if val_metrics:\n","                for key, value in val_metrics.items():\n","                    if key in self.history and value is not None:\n","                        try:\n","                            self.history[key].append(float(value))\n","                        except (ValueError, TypeError):\n","                            print(f\"Warning: Could not convert {key}={value} to float\")\n","\n","            # Print metrics safely\n","            print(f\"Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}\")\n","\n","            if val_metrics:\n","                print(f\"RMSE: {val_metrics.get('rmse', 'N/A'):.4f} | \"\n","                      f\"Translation: {val_metrics.get('translation_error', 'N/A'):.4f}mm | \"\n","                      f\"Rotation: {val_metrics.get('rotation_error_degrees', 'N/A'):.2f}°\")\n","                print(f\"Surface Dice: {val_metrics.get('surface_dice', 'N/A'):.4f} | \"\n","                      f\"Chamfer: {val_metrics.get('chamfer_distance', 'N/A'):.4f}\")\n","\n","            # Early stopping logic\n","            if val_loss < best_loss:\n","                best_loss = val_loss\n","                patience_counter = 0\n","\n","                # Save best model\n","                torch.save({\n","                    'epoch': epoch,\n","                    'model_state_dict': self.model.state_dict(),\n","                    'optimizer_state_dict': optimizer.state_dict(),\n","                    'best_val_loss': best_loss,\n","                    'history': self.history\n","                }, self.save_dir / 'best_model.pth')\n","\n","                torch.save(self.model.state_dict(), self.save_dir / 'best_model_state_dict.pth')\n","                print(f\"✓ Best model saved: {val_loss:.6f}\")\n","            else:\n","                patience_counter += 1\n","                print(f\"No improvement for {patience_counter}/{patience} epochs\")\n","\n","                if patience_counter >= patience:\n","                    print(f\"Early stopping triggered after {epoch+1} epochs\")\n","                    break\n","\n","        # Save final model\n","        torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': self.model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'final_train_loss': train_loss,\n","            'final_val_loss': val_loss,\n","            'best_val_loss': best_loss,\n","            'complete_history': self.history\n","        }, self.save_dir / 'final_model.pth')\n","\n","        torch.save(self.model.state_dict(), self.save_dir / 'final_model_state_dict.pth')\n","        print(f\"✓ Final model saved\")\n","\n","        self.plot_training_curves()\n","        return self.history\n","\n","    def plot_training_curves(self):\n","        \"\"\"FIXED: Handle missing data gracefully\"\"\"\n","        try:\n","            fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n","            fig.suptitle('STSR 2025 Training Progress - All Official Metrics', fontsize=16, fontweight='bold')\n","\n","            # Loss curves\n","            if self.history['train_loss'] and self.history['val_loss']:\n","                axes[0, 0].plot(self.history['train_loss'], label='Train Loss', linewidth=2)\n","                axes[0, 0].plot(self.history['val_loss'], label='Val Loss', linewidth=2)\n","                axes[0, 0].set_title('Training Loss', fontweight='bold')\n","                axes[0, 0].set_xlabel('Epoch')\n","                axes[0, 0].set_ylabel('Loss')\n","                axes[0, 0].legend()\n","                axes[0, 0].grid(True, alpha=0.3)\n","\n","            # FIXED: Safe plotting with existence checks\n","            metrics_to_plot = [\n","                ('rmse', 'RMSE (Official Metric)', 'red', (0, 1)),\n","                ('ncc', 'Normalized Cross-Correlation', 'green', (0, 2)),\n","                ('nmi', 'Normalized Mutual Information', 'blue', (1, 0)),\n","                ('surface_dice', 'Surface Dice Coefficient', 'purple', (1, 1)),\n","                ('chamfer_distance', 'Chamfer Distance', 'orange', (1, 2)),\n","                ('translation_error', 'Translation Error (mm)', 'brown', (2, 0)),\n","                ('rotation_error_degrees', 'Rotation Error (degrees)', 'pink', (2, 1))\n","            ]\n","\n","            for metric, title, color, pos in metrics_to_plot:\n","                if metric in self.history and self.history[metric] and len(self.history[metric]) > 0:\n","                    axes[pos].plot(self.history[metric], color=color, linewidth=2)\n","                    axes[pos].set_title(title, fontweight='bold')\n","                    axes[pos].set_xlabel('Epoch')\n","                    axes[pos].set_ylabel(metric.replace('_', ' ').title())\n","                    axes[pos].grid(True, alpha=0.3)\n","                else:\n","                    axes[pos].text(0.5, 0.5, f'No {metric} data', ha='center', va='center',\n","                                transform=axes[pos].transAxes)\n","                    axes[pos].set_title(title, fontweight='bold')\n","\n","            # Model info\n","            axes[2, 2].text(0.5, 0.5,\n","                          'STSR 2025 Model:\\n\\n'\n","                          '• PointNet Feature Extraction\\n'\n","                          '• PointNetLK Registration\\n'\n","                          '• Lucas-Kanade Optimization\\n'\n","                          '• Official STSR Evaluation\\n'\n","                          '• 800 HU CBCT Threshold\\n'\n","                          '• GitHub Standard Processing',\n","                          ha='center', va='center', transform=axes[2, 2].transAxes,\n","                          fontsize=11, bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n","            axes[2, 2].set_title('Model Architecture', fontweight='bold')\n","            axes[2, 2].axis('off')\n","\n","            plt.tight_layout()\n","            plt.savefig(self.save_dir / 'training_curves_complete.png', dpi=300, bbox_inches='tight')\n","            plt.close()\n","\n","            print(f\"✓ Training curves saved to: {self.save_dir / 'training_curves_complete.png'}\")\n","\n","        except Exception as e:\n","            print(f\"Warning: Could not generate training curves: {e}\")\n","\n","# ============================================================================\n","# INFERENCE AND SUBMISSION\n","# ============================================================================\n","\n","def generate_submission(model, test_loader, output_dir):\n","    \"\"\"Generate submission file with predictions\"\"\"\n","    model.eval()\n","    output_dir = Path(output_dir)\n","    output_dir.mkdir(parents=True, exist_ok=True)\n","\n","    predictions = {}\n","\n","    with torch.no_grad():\n","        for batch in tqdm(test_loader, desc=\"Generating predictions\"):\n","            cbct = batch['cbct'].to(next(model.parameters()).device)\n","            stl = batch['stl'].to(next(model.parameters()).device)\n","            case_ids = batch['case_id']\n","\n","            # Predict transformations\n","            predicted_transforms = model(stl, cbct)\n","\n","            # Save predictions\n","            for i, case_id in enumerate(case_ids):\n","                case_dir = output_dir / case_id\n","                case_dir.mkdir(exist_ok=True)\n","\n","                transform = predicted_transforms[i].cpu().numpy()\n","\n","                # Save both upper and lower transformations\n","                # (In practice, you might want separate predictions)\n","                np.save(case_dir / \"upper_gt.npy\", transform)\n","                np.save(case_dir / \"lower_gt.npy\", transform)\n","\n","                predictions[case_id] = transform\n","\n","    # Create submission zip\n","    import zipfile\n","    zip_path = output_dir / \"submission.zip\"\n","    with zipfile.ZipFile(zip_path, 'w') as zipf:\n","        for case_dir in output_dir.iterdir():\n","            if case_dir.is_dir() and case_dir.name != '__pycache__':\n","                for file in case_dir.glob(\"*_gt.npy\"):\n","                    arcname = f\"{case_dir.name}/{file.name}\"\n","                    zipf.write(file, arcname)\n","\n","    print(f\"Submission saved to: {zip_path}\")\n","    return predictions\n","\n","# ============================================================================\n","# MAIN EXECUTION\n","# ============================================================================\n","\n","def main():\n","    \"\"\"Main training and evaluation pipeline\"\"\"\n","\n","    # Configuration\n","    config = {\n","        'data_root': \"/content/drive/MyDrive/Papers/STS_2025/VERSION2/DATASET\",\n","        'save_dir': \"/content/drive/MyDrive/Papers/STS_2025/VERSION2/RESULTS_OFFICIAL\",\n","        'batch_size': 4,\n","        'num_epochs': 50,\n","        'learning_rate': 5e-4,\n","        'n_points': 2048,\n","        'feature_dim': 1024,\n","        'num_iterations': 5\n","    }\n","\n","    # Setup\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    print(f\"Using device: {device}\")\n","\n","    # Create datasets\n","    print(\"Creating datasets...\")\n","    train_dataset = STSRDataset(\n","        root_dir=config['data_root'],\n","        n_points=config['n_points'],\n","        mode='train',\n","        augment=True\n","    )\n","\n","    val_dataset = STSRDataset(\n","        root_dir=config['data_root'],\n","        n_points=config['n_points'],\n","        mode='val',\n","        augment=False\n","    )\n","\n","    test_dataset = STSRDataset(\n","        root_dir=config['data_root'],\n","        n_points=config['n_points'],\n","        mode='test',\n","        augment=False\n","    )\n","\n","    # Create data loaders\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=config['batch_size'],\n","        shuffle=True,\n","        num_workers=2,\n","        pin_memory=True,\n","        drop_last=True\n","    )\n","\n","    val_loader = DataLoader(\n","        val_dataset,\n","        batch_size=config['batch_size'],\n","        shuffle=False,\n","        num_workers=2,\n","        pin_memory=True,\n","        drop_last=True\n","    )\n","\n","    test_loader = DataLoader(\n","        test_dataset,\n","        batch_size=config['batch_size'],\n","        shuffle=False,\n","        num_workers=2,\n","        pin_memory=True\n","    )\n","\n","    print(f\"Dataset sizes - Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n","\n","    # Create model\n","    print(\"Creating model...\")\n","    model = STSRModel(\n","        feature_dim=config['feature_dim'],\n","        num_iterations=config['num_iterations']\n","    ).to(device)\n","\n","    # Count parameters\n","    total_params = sum(p.numel() for p in model.parameters())\n","    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    print(f\"Model parameters - Total: {total_params:,}, Trainable: {trainable_params:,}\")\n","\n","    # Create trainer\n","    trainer = STSRTrainer(model, device, config['save_dir'])\n","\n","    # Train model\n","    print(\"\\nStarting training...\")\n","    history = trainer.train(\n","        train_loader,\n","        val_loader,\n","        config['num_epochs'],\n","        config['learning_rate']\n","    )\n","\n","    # Save training history\n","    with open(trainer.save_dir / 'training_history.json', 'w') as f:\n","        json.dump({k: [float(x) for x in v] for k, v in history.items()}, f, indent=2)\n","\n","    # Load best model for inference\n","    print(\"\\nLoading best model for inference...\")\n","\n","    # FIXED: Load only state dict, not entire checkpoint\n","    try:\n","        checkpoint = torch.load(trainer.save_dir / 'best_model_state_dict.pth')\n","        model.load_state_dict(checkpoint)\n","        print(\"✓ Model loaded successfully\")\n","    except Exception as e:\n","        print(f\"Warning: Could not load best model: {e}\")\n","        print(\"Using final model instead...\")\n","        checkpoint = torch.load(trainer.save_dir / 'final_model_state_dict.pth')\n","        model.load_state_dict(checkpoint)\n","\n","    # Generate predictions\n","    #print(\"Generating test predictions...\")\n","    ##predictions = generate_submission(model, test_loader, trainer.save_dir / \"predictions\")\n","\n","    # Final evaluation on validation set\n","    print(\"\\nFinal evaluation on validation set:\")\n","    final_loss, final_metrics = trainer.validate_epoch(val_loader)\n","\n","    print(f\"\\nFinal Results:\")\n","    print(f\"Validation Loss: {final_loss:.6f}\")\n","    print(f\"RMSE: {final_metrics['rmse']:.4f} mm\")\n","    print(f\"NCC: {final_metrics['ncc']:.4f}\")\n","    print(f\"NMI: {final_metrics['nmi']:.4f}\")\n","    print(f\"Surface Dice: {final_metrics['surface_dice']:.4f}\")\n","    print(f\"Chamfer Distance: {final_metrics['chamfer_distance']:.4f}\")\n","    print(f\"Translation Error: {final_metrics['translation_error']:.4f} mm\")\n","    print(f\"Rotation Error: {final_metrics['rotation_error_degrees']:.2f} degrees\")\n","\n","    # Save final results\n","    final_results = {\n","        'final_loss': final_loss,\n","        'final_metrics': final_metrics,\n","        'config': config,\n","        'model_parameters': {\n","            'total': total_params,\n","            'trainable': trainable_params\n","        }\n","    }\n","\n","    with open(trainer.save_dir / 'final_results.json', 'w') as f:\n","        json.dump(final_results, f, indent=2, default=str)\n","\n","    print(f\"\\nAll results saved to: {trainer.save_dir}\")\n","    print(\"Training completed successfully!\")\n","\n","    return model, history, final_results\n","\n","# ============================================================================\n","# QUICK VERIFICATION FUNCTION\n","# ============================================================================\n","\n","def verify_data_loading():\n","    \"\"\"Quick verification that data loading works correctly\"\"\"\n","    print(\"Verifying data loading...\")\n","\n","    # Test dataset creation\n","    dataset = STSRDataset(\n","        root_dir=\"/content/drive/MyDrive/Papers/STS_2025/VERSION2/DATASET\",\n","        n_points=1024,  # Smaller for testing\n","        mode='train',\n","        augment=False\n","    )\n","\n","    if len(dataset) == 0:\n","        print(\"❌ No data found! Check your data paths.\")\n","        return False\n","\n","    # Test data loading\n","    try:\n","        sample = dataset[0]\n","        print(f\"✅ Successfully loaded sample:\")\n","        print(f\"   CBCT shape: {sample['cbct'].shape}\")\n","        print(f\"   STL shape: {sample['stl'].shape}\")\n","        print(f\"   Target shape: {sample['target'].shape}\")\n","        print(f\"   GT transform shape: {sample['gt_transform'].shape}\")\n","        print(f\"   Case ID: {sample['case_id']}\")\n","        return True\n","    except Exception as e:\n","        print(f\"❌ Error loading data: {e}\")\n","        return False\n","\n","# ============================================================================\n","# EXECUTION\n","# ============================================================================\n","\n","if __name__ == \"__main__\":\n","    # Verify data loading first\n","    if verify_data_loading():\n","        print(\"\\n\" + \"=\"*60)\n","        print(\"STARTING STSR 2025 OFFICIAL TRAINING\")\n","        print(\"=\"*60)\n","\n","        # Run main training\n","        model, history, results = main()\n","\n","        print(\"\\n\" + \"=\"*60)\n","        print(\"TRAINING COMPLETED SUCCESSFULLY!\")\n","        print(\"=\"*60)\n","    else:\n","        print(\"❌ Data verification failed. Please check your data paths.\")\n"]},{"cell_type":"markdown","source":["#Pseudo Label create"],"metadata":{"id":"3J4MpNgi9b79"}},{"cell_type":"code","source":["\"\"\"\n","DIRECT Pseudo-Label Generation -\n","Loads CBCT + STL, applies model, applies ICP, saves pseudo-label\n","\"\"\"\n","\n","import torch\n","import numpy as np\n","import open3d as o3d\n","from pathlib import Path\n","from tqdm import tqdm\n","import zipfile\n","import nibabel as nib\n","\n","def simple_icp_refinement(source_points, target_points, initial_transform, max_iter=20):\n","    \"\"\"\n","    Simple ICP - no scipy dependencies\n","    \"\"\"\n","    try:\n","        # Apply initial transform\n","        source_h = np.hstack([source_points, np.ones((len(source_points), 1))])\n","        transformed_source = (initial_transform @ source_h.T).T[:, :3]\n","\n","        # Subsample for speed\n","        if len(transformed_source) > 1000:\n","            idx = np.random.choice(len(transformed_source), 1000, replace=False)\n","            transformed_source = transformed_source[idx]\n","            source_subset = source_points[idx]\n","        else:\n","            source_subset = source_points\n","\n","        if len(target_points) > 1000:\n","            idx = np.random.choice(len(target_points), 1000, replace=False)\n","            target_subset = target_points[idx]\n","        else:\n","            target_subset = target_points\n","\n","        current_transform = np.eye(4)\n","        current_source = transformed_source.copy()\n","\n","        for i in range(max_iter):\n","            # Find closest points (simple distance calculation)\n","            distances = np.linalg.norm(current_source[:, np.newaxis] - target_subset, axis=2)\n","            closest_idx = np.argmin(distances, axis=1)\n","            closest_distances = np.min(distances, axis=1)\n","\n","            # Keep only good matches (70th percentile)\n","            threshold = np.percentile(closest_distances, 70)\n","            good_mask = closest_distances <= threshold\n","\n","            if np.sum(good_mask) < 20:\n","                break\n","\n","            good_source = current_source[good_mask]\n","            good_target = target_subset[closest_idx[good_mask]]\n","\n","            # Compute centroids\n","            src_center = np.mean(good_source, axis=0)\n","            tgt_center = np.mean(good_target, axis=0)\n","\n","            # Simple translation update\n","            translation = tgt_center - src_center\n","            current_source += translation\n","\n","            # Update transform\n","            delta_T = np.eye(4)\n","            delta_T[:3, 3] = translation\n","            current_transform = delta_T @ current_transform\n","\n","            # Check if converged\n","            if np.linalg.norm(translation) < 0.5:\n","                break\n","\n","        # Combine transforms\n","        final_transform = current_transform @ initial_transform\n","        return final_transform\n","\n","    except Exception as e:\n","        print(f\"ICP failed: {e}\")\n","        return initial_transform\n","\n","def generate_single_pseudo_label(model, case_id, data_root, device):\n","    \"\"\"\n","    Generate pseudo-label for ONE case\n","    Returns: transform matrix or None if failed\n","    \"\"\"\n","    # Build path to case\n","    case_path = Path(data_root) / \"Unlabeled_300\" / \"Images\" / case_id\n","\n","    if not case_path.exists():\n","        return None\n","\n","    # Load CBCT\n","    cbct_file = case_path / \"CBCT.nii.gz\"\n","    if not cbct_file.exists():\n","        return None\n","\n","    try:\n","        cbct_img = nib.load(str(cbct_file))\n","        cbct_data = cbct_img.get_fdata()\n","\n","        # Extract bone points (800 HU threshold)\n","        bone_voxels = np.argwhere(cbct_data > 800)\n","        if len(bone_voxels) < 100:\n","            return None\n","\n","        # Convert to world coordinates\n","        voxel_coords = bone_voxels[:, [2, 1, 0]]  # x,y,z order\n","        world_coords = np.hstack([voxel_coords, np.ones((len(voxel_coords), 1))])\n","        cbct_points = (cbct_img.affine @ world_coords.T).T[:, :3]\n","\n","    except Exception as e:\n","        print(f\"CBCT loading failed for {case_id}: {e}\")\n","        return None\n","\n","    # Load STL files\n","    stl_points = []\n","\n","    # Try upper STL\n","    upper_file = case_path / \"upper.stl\"\n","    if upper_file.exists():\n","        try:\n","            upper_mesh = o3d.io.read_triangle_mesh(str(upper_file))\n","            if len(upper_mesh.vertices) > 0:\n","                stl_points.append(np.asarray(upper_mesh.vertices))\n","        except:\n","            pass\n","\n","    # Try lower STL\n","    lower_file = case_path / \"lower.stl\"\n","    if lower_file.exists():\n","        try:\n","            lower_mesh = o3d.io.read_triangle_mesh(str(lower_file))\n","            if len(lower_mesh.vertices) > 0:\n","                stl_points.append(np.asarray(lower_mesh.vertices))\n","        except:\n","            pass\n","\n","    # Check if we have STL data\n","    if len(stl_points) == 0:\n","        return None\n","\n","    # Combine STL points\n","    combined_stl = np.vstack(stl_points)\n","\n","    # Subsample for memory\n","    if len(cbct_points) > 8000:\n","        idx = np.random.choice(len(cbct_points), 8000, replace=False)\n","        cbct_points = cbct_points[idx]\n","\n","    if len(combined_stl) > 8000:\n","        idx = np.random.choice(len(combined_stl), 8000, replace=False)\n","        combined_stl = combined_stl[idx]\n","\n","    # Normalize for model\n","    all_points = np.vstack([cbct_points, combined_stl])\n","    center = np.mean(all_points, axis=0)\n","    scale = np.max(np.linalg.norm(all_points - center, axis=1))\n","\n","    if scale < 1e-6:\n","        return None\n","\n","    cbct_norm = (cbct_points - center) / scale\n","    stl_norm = (combined_stl - center) / scale\n","\n","    # Sample exactly 1024 points for model\n","    def sample_1024(points):\n","        if len(points) >= 1024:\n","            idx = np.random.choice(len(points), 1024, replace=False)\n","        else:\n","            idx = np.random.choice(len(points), 1024, replace=True)\n","        return points[idx]\n","\n","    cbct_1024 = sample_1024(cbct_norm)\n","    stl_1024 = sample_1024(stl_norm)\n","\n","    # Apply model\n","    try:\n","        model.eval()\n","        with torch.no_grad():\n","            cbct_tensor = torch.from_numpy(cbct_1024).float().unsqueeze(0).to(device)\n","            stl_tensor = torch.from_numpy(stl_1024).float().unsqueeze(0).to(device)\n","\n","            pred_transform = model(cbct_tensor, stl_tensor)\n","            pred_transform = pred_transform[0].cpu().numpy()\n","    except Exception as e:\n","        print(f\"Model prediction failed for {case_id}: {e}\")\n","        return None\n","\n","    # Denormalize transformation\n","    S = np.eye(4)\n","    S[:3, :3] *= scale\n","    S[:3, 3] = center\n","\n","    S_inv = np.eye(4)\n","    S_inv[:3, :3] /= scale\n","    S_inv[:3, 3] = -center / scale\n","\n","    transform_raw = S @ pred_transform @ S_inv\n","\n","    # Apply ICP refinement\n","    try:\n","        refined_transform = simple_icp_refinement(combined_stl, cbct_points, transform_raw)\n","\n","        # Quick quality check\n","        stl_h = np.hstack([combined_stl, np.ones((len(combined_stl), 1))])\n","        aligned_stl = (refined_transform @ stl_h.T).T[:, :3]\n","\n","        cbct_center = np.mean(cbct_points, axis=0)\n","        aligned_center = np.mean(aligned_stl, axis=0)\n","        final_distance = np.linalg.norm(cbct_center - aligned_center)\n","\n","        # Reject if completely wrong\n","        if final_distance > 500:  # 50cm is probably wrong\n","            return None\n","\n","        return refined_transform\n","\n","    except Exception as e:\n","        print(f\"ICP failed for {case_id}: {e}\")\n","        return transform_raw  # Return model prediction if ICP fails\n","\n","def batch_generate_pseudo_labels(model, data_root, output_dir, device, max_cases=None):\n","    \"\"\"\n","    Generate pseudo-labels for all valid cases\n","    \"\"\"\n","    # Load model weights\n","    model_path = \"/content/drive/MyDrive/Papers/STS_2025/VERSION2/RESULTS_OFFICIAL/best_model_state_dict.pth\"\n","    model.load_state_dict(torch.load(model_path, map_location=device))\n","\n","    # Find all case directories\n","    unlabeled_dir = Path(data_root) / \"Unlabeled_300\" / \"Images\"\n","    if not unlabeled_dir.exists():\n","        print(f\"ERROR: {unlabeled_dir} does not exist!\")\n","        return 0\n","\n","    case_dirs = [d.name for d in unlabeled_dir.iterdir() if d.is_dir()]\n","    case_dirs.sort()  # Process in order\n","\n","    if max_cases:\n","        case_dirs = case_dirs[:max_cases]\n","\n","    print(f\"Found {len(case_dirs)} cases to process\")\n","\n","    # Output directory\n","    output_path = Path(output_dir)\n","    output_path.mkdir(parents=True, exist_ok=True)\n","\n","    # Process each case\n","    successful = 0\n","    failed_cases = []\n","\n","    for case_id in tqdm(case_dirs, desc=\"Generating pseudo-labels\"):\n","        transform = generate_single_pseudo_label(model, case_id, data_root, device)\n","\n","        if transform is not None:\n","            # Save pseudo-labels\n","            case_out_dir = output_path / case_id\n","            case_out_dir.mkdir(exist_ok=True)\n","\n","            # Save same transform for upper and lower\n","            # (You might want to generate separate transforms later)\n","            np.save(case_out_dir / \"upper_gt.npy\", transform)\n","            np.save(case_out_dir / \"lower_gt.npy\", transform)\n","\n","            successful += 1\n","        else:\n","            failed_cases.append(case_id)\n","\n","    print(f\"\\nResults:\")\n","    print(f\"Successful: {successful}/{len(case_dirs)}\")\n","    print(f\"Failed cases: {len(failed_cases)}\")\n","\n","    if len(failed_cases) > 0 and len(failed_cases) < 20:\n","        print(f\"Failed cases: {failed_cases}\")\n","\n","    # Create zip file\n","    if successful > 0:\n","        zip_path = output_path / \"pseudo_labels_simple.zip\"\n","        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n","            for case_dir in output_path.iterdir():\n","                if case_dir.is_dir():\n","                    for npy_file in case_dir.glob(\"*.npy\"):\n","                        arcname = f\"{case_dir.name}/{npy_file.name}\"\n","                        zipf.write(npy_file, arcname)\n","\n","        print(f\"Pseudo-labels saved to: {zip_path}\")\n","\n","    return successful\n","\n","# USAGE:\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = STSRModel(feature_dim=1024, num_iterations=3).to(device)\n","data_root = \"/content/drive/MyDrive/Papers/STS_2025/VERSION2/DATASET\"\n","output_dir = \"/content/drive/MyDrive/Papers/STS_2025/VERSION2/PSEUDO_LABELS_SIMPLE\"\n","#\n","num_generated = batch_generate_pseudo_labels(model, data_root, output_dir, device)\n","print(f\"Generated {num_generated} pseudo-labels\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xQ0XTRARoZk2","executionInfo":{"status":"ok","timestamp":1758540523360,"user_tz":-330,"elapsed":4356664,"user":{"displayName":"Gadha Lekshmi P","userId":"03692891214075285585"}},"outputId":"68a3fa9b-c32e-4409-cab5-9f51ec997860"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 300 cases to process\n"]},{"output_type":"stream","name":"stderr","text":["Generating pseudo-labels:  44%|████▍     | 132/300 [31:55<31:20, 11.19s/it]"]},{"output_type":"stream","name":"stdout","text":["\u001b[1;33m[Open3D WARNING] Unable to load file /content/drive/MyDrive/Papers/STS_2025/VERSION2/DATASET/Unlabeled_300/Images/133/upper.stl with ASSIMP: Failed to determine STL storage representation for /content/drive/MyDrive/Papers/STS_2025/VERSION2/DATASET/Unlabeled_300/Images/133/upper.stl.\u001b[0;m\n"]},{"output_type":"stream","name":"stderr","text":["\rGenerating pseudo-labels:  44%|████▍     | 133/300 [32:05<29:49, 10.72s/it]"]},{"output_type":"stream","name":"stdout","text":["\u001b[1;33m[Open3D WARNING] Unable to load file /content/drive/MyDrive/Papers/STS_2025/VERSION2/DATASET/Unlabeled_300/Images/133/lower.stl with ASSIMP: Failed to determine STL storage representation for /content/drive/MyDrive/Papers/STS_2025/VERSION2/DATASET/Unlabeled_300/Images/133/lower.stl.\u001b[0;m\n"]},{"output_type":"stream","name":"stderr","text":["Generating pseudo-labels: 100%|██████████| 300/300 [1:10:13<00:00, 14.04s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Results:\n","Successful: 288/300\n","Failed cases: 12\n","Failed cases: ['008', '010', '014', '058', '086', '112', '113', '128', '132', '133', '136', '162']\n","Pseudo-labels saved to: /content/drive/MyDrive/Papers/STS_2025/VERSION2/PSEUDO_LABELS_SIMPLE/pseudo_labels_simple.zip\n","Generated 288 pseudo-labels\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Test Pseudo-Label Quality and Apply Additional ICP if Needed\n","\"\"\"\n","\n","import torch\n","import numpy as np\n","import open3d as o3d\n","from pathlib import Path\n","from tqdm import tqdm\n","import nibabel as nib\n","from scipy.spatial.distance import cdist\n","\n","def load_case_data(case_id, data_root):\n","    \"\"\"Load CBCT and STL data for a case\"\"\"\n","    case_path = Path(data_root) / \"Unlabeled_300\" / \"Images\" / case_id\n","\n","    # Load CBCT\n","    cbct_file = case_path / \"CBCT.nii.gz\"\n","    cbct_img = nib.load(str(cbct_file))\n","    cbct_data = cbct_img.get_fdata()\n","\n","    # Extract bone points\n","    bone_voxels = np.argwhere(cbct_data > 800)\n","    voxel_coords = bone_voxels[:, [2, 1, 0]]\n","    world_coords = np.hstack([voxel_coords, np.ones((len(voxel_coords), 1))])\n","    cbct_points = (cbct_img.affine @ world_coords.T).T[:, :3]\n","\n","    # Subsample CBCT\n","    if len(cbct_points) > 5000:\n","        idx = np.random.choice(len(cbct_points), 5000, replace=False)\n","        cbct_points = cbct_points[idx]\n","\n","    # Load STL files\n","    stl_points = []\n","\n","    upper_file = case_path / \"upper.stl\"\n","    if upper_file.exists():\n","        try:\n","            upper_mesh = o3d.io.read_triangle_mesh(str(upper_file))\n","            if len(upper_mesh.vertices) > 0:\n","                stl_points.append(np.asarray(upper_mesh.vertices))\n","        except:\n","            pass\n","\n","    lower_file = case_path / \"lower.stl\"\n","    if lower_file.exists():\n","        try:\n","            lower_mesh = o3d.io.read_triangle_mesh(str(lower_file))\n","            if len(lower_mesh.vertices) > 0:\n","                stl_points.append(np.asarray(lower_mesh.vertices))\n","        except:\n","            pass\n","\n","    if not stl_points:\n","        return None, None\n","\n","    combined_stl = np.vstack(stl_points)\n","\n","    # Subsample STL\n","    if len(combined_stl) > 5000:\n","        idx = np.random.choice(len(combined_stl), 5000, replace=False)\n","        combined_stl = combined_stl[idx]\n","\n","    return cbct_points, combined_stl\n","\n","def evaluate_pseudo_label(case_id, pseudo_labels_dir, data_root):\n","    \"\"\"Evaluate quality of a single pseudo-label\"\"\"\n","\n","    # Load pseudo-label\n","    case_pseudo_dir = Path(pseudo_labels_dir) / case_id\n","    upper_gt_file = case_pseudo_dir / \"upper_gt.npy\"\n","\n","    if not upper_gt_file.exists():\n","        return None\n","\n","    transform = np.load(upper_gt_file)\n","\n","    # Load case data\n","    cbct_points, stl_points = load_case_data(case_id, data_root)\n","    if cbct_points is None or stl_points is None:\n","        return None\n","\n","    # Apply transformation\n","    stl_h = np.hstack([stl_points, np.ones((len(stl_points), 1))])\n","    aligned_stl = (transform @ stl_h.T).T[:, :3]\n","\n","    # Calculate metrics\n","    cbct_center = np.mean(cbct_points, axis=0)\n","    stl_original_center = np.mean(stl_points, axis=0)\n","    aligned_center = np.mean(aligned_stl, axis=0)\n","\n","    original_distance = np.linalg.norm(cbct_center - stl_original_center)\n","    final_distance = np.linalg.norm(cbct_center - aligned_center)\n","    improvement = original_distance - final_distance\n","\n","    # Chamfer distance (simplified)\n","    try:\n","        distances = cdist(aligned_stl, cbct_points)\n","        chamfer = np.mean(np.min(distances, axis=1))\n","    except:\n","        chamfer = float('inf')\n","\n","    # Quality assessment\n","    if improvement > 50 and final_distance < 100 and chamfer < 50:\n","        quality = \"GOOD\"\n","    elif improvement > 10 and final_distance < 200 and chamfer < 100:\n","        quality = \"FAIR\"\n","    else:\n","        quality = \"POOR\"\n","\n","    return {\n","        'case_id': case_id,\n","        'original_distance': original_distance,\n","        'final_distance': final_distance,\n","        'improvement': improvement,\n","        'chamfer': chamfer,\n","        'quality': quality,\n","        'transform': transform,\n","        'cbct_points': cbct_points,\n","        'stl_points': stl_points\n","    }\n","\n","def advanced_icp_refinement(source_points, target_points, initial_transform, max_iter=30):\n","    \"\"\"More aggressive ICP refinement\"\"\"\n","    try:\n","        current_transform = initial_transform.copy()\n","\n","        # Apply initial transform\n","        source_h = np.hstack([source_points, np.ones((len(source_points), 1))])\n","        current_source = (current_transform @ source_h.T).T[:, :3]\n","\n","        prev_error = float('inf')\n","\n","        for i in range(max_iter):\n","            # Find correspondences\n","            distances = cdist(current_source, target_points)\n","            nearest_idx = np.argmin(distances, axis=1)\n","            min_distances = np.min(distances, axis=1)\n","\n","            # Dynamic outlier rejection (more aggressive)\n","            percentile = max(50, 90 - i * 2)  # Start strict, become lenient\n","            threshold = np.percentile(min_distances, percentile)\n","            valid_mask = min_distances <= threshold\n","\n","            if np.sum(valid_mask) < 50:\n","                break\n","\n","            valid_source = current_source[valid_mask]\n","            valid_target = target_points[nearest_idx[valid_mask]]\n","\n","            # Compute transformation\n","            src_centroid = np.mean(valid_source, axis=0)\n","            tgt_centroid = np.mean(valid_target, axis=0)\n","\n","            # Center points\n","            src_centered = valid_source - src_centroid\n","            tgt_centered = valid_target - tgt_centroid\n","\n","            # SVD for rotation\n","            H = src_centered.T @ tgt_centered\n","            U, _, Vt = np.linalg.svd(H)\n","            R = Vt.T @ U.T\n","\n","            # Ensure proper rotation\n","            if np.linalg.det(R) < 0:\n","                Vt[-1, :] *= -1\n","                R = Vt.T @ U.T\n","\n","            # Translation\n","            t = tgt_centroid - R @ src_centroid\n","\n","            # Build incremental transform\n","            delta_T = np.eye(4)\n","            delta_T[:3, :3] = R\n","            delta_T[:3, 3] = t\n","\n","            # Update\n","            current_transform = delta_T @ current_transform\n","            current_source = (delta_T[:3, :3] @ current_source.T).T + delta_T[:3, 3]\n","\n","            # Check convergence\n","            current_error = np.mean(min_distances[valid_mask])\n","            if abs(prev_error - current_error) < 0.1:\n","                break\n","            prev_error = current_error\n","\n","        return current_transform\n","\n","    except Exception as e:\n","        return initial_transform\n","\n","def test_and_improve_pseudo_labels(pseudo_labels_dir, data_root, output_dir=None, apply_additional_icp=True):\n","    \"\"\"Test pseudo-label quality and optionally apply additional ICP\"\"\"\n","\n","    pseudo_path = Path(pseudo_labels_dir)\n","    if output_dir:\n","        output_path = Path(output_dir)\n","        output_path.mkdir(parents=True, exist_ok=True)\n","\n","    # Find all pseudo-labeled cases\n","    case_dirs = [d.name for d in pseudo_path.iterdir() if d.is_dir()]\n","    case_dirs.sort()\n","\n","    results = []\n","    improved_count = 0\n","\n","    print(f\"Testing {len(case_dirs)} pseudo-labels...\")\n","\n","    for case_id in tqdm(case_dirs[:20], desc=\"Testing pseudo-labels\"):  # Test first 20\n","        result = evaluate_pseudo_label(case_id, pseudo_labels_dir, data_root)\n","\n","        if result is None:\n","            continue\n","\n","        original_quality = result['quality']\n","        original_improvement = result['improvement']\n","\n","        # Apply additional ICP if requested and quality is not GOOD\n","        if apply_additional_icp and result['quality'] != 'GOOD':\n","            try:\n","                refined_transform = advanced_icp_refinement(\n","                    result['stl_points'],\n","                    result['cbct_points'],\n","                    result['transform']\n","                )\n","\n","                # Re-evaluate with refined transform\n","                stl_h = np.hstack([result['stl_points'], np.ones((len(result['stl_points']), 1))])\n","                new_aligned = (refined_transform @ stl_h.T).T[:, :3]\n","\n","                cbct_center = np.mean(result['cbct_points'], axis=0)\n","                new_center = np.mean(new_aligned, axis=0)\n","                new_distance = np.linalg.norm(cbct_center - new_center)\n","                new_improvement = result['original_distance'] - new_distance\n","\n","                # Check if ICP improved the result\n","                if new_improvement > original_improvement + 5:  # At least 5mm better\n","                    result['final_distance'] = new_distance\n","                    result['improvement'] = new_improvement\n","                    result['transform'] = refined_transform\n","\n","                    # Update quality\n","                    if new_improvement > 50 and new_distance < 100:\n","                        result['quality'] = \"GOOD\"\n","                    elif new_improvement > 10 and new_distance < 200:\n","                        result['quality'] = \"FAIR\"\n","\n","                    if result['quality'] != original_quality:\n","                        improved_count += 1\n","                        print(f\"  {case_id}: {original_quality} -> {result['quality']} \"\n","                              f\"({original_improvement:.1f} -> {new_improvement:.1f}mm)\")\n","            except:\n","                pass  # Keep original if ICP fails\n","\n","        results.append(result)\n","\n","        # Save improved pseudo-label if output directory provided\n","        if output_dir and result['quality'] in ['GOOD', 'FAIR']:\n","            case_out_dir = output_path / case_id\n","            case_out_dir.mkdir(exist_ok=True)\n","            np.save(case_out_dir / \"upper_gt.npy\", result['transform'])\n","            np.save(case_out_dir / \"lower_gt.npy\", result['transform'])\n","\n","    # Summary statistics\n","    quality_counts = {'GOOD': 0, 'FAIR': 0, 'POOR': 0}\n","    improvements = []\n","    final_distances = []\n","\n","    for r in results:\n","        quality_counts[r['quality']] += 1\n","        improvements.append(r['improvement'])\n","        final_distances.append(r['final_distance'])\n","\n","    print(f\"\\nPseudo-Label Quality Assessment (first 20 cases):\")\n","    print(f\"GOOD: {quality_counts['GOOD']}/20\")\n","    print(f\"FAIR: {quality_counts['FAIR']}/20\")\n","    print(f\"POOR: {quality_counts['POOR']}/20\")\n","    print(f\"Average improvement: {np.mean(improvements):.1f}mm\")\n","    print(f\"Average final distance: {np.mean(final_distances):.1f}mm\")\n","\n","    if apply_additional_icp:\n","        print(f\"ICP improved {improved_count} cases\")\n","\n","    # Recommendation\n","    good_ratio = quality_counts['GOOD'] / len(results)\n","    fair_ratio = quality_counts['FAIR'] / len(results)\n","\n","    if good_ratio > 0.3 or (good_ratio + fair_ratio) > 0.6:\n","        recommendation = \"PROCEED - Pseudo-labels look reasonable for training\"\n","        use_for_training = True\n","    else:\n","        recommendation = \"CAUTION - Many poor quality pseudo-labels detected\"\n","        use_for_training = False\n","\n","    print(f\"\\nRecommendation: {recommendation}\")\n","\n","    return {\n","        'results': results,\n","        'quality_counts': quality_counts,\n","        'avg_improvement': np.mean(improvements),\n","        'avg_final_distance': np.mean(final_distances),\n","        'improved_by_icp': improved_count,\n","        'use_for_training': use_for_training\n","    }\n","\n","# Usage\n","if __name__ == \"__main__\":\n","    pseudo_labels_dir = \"/content/drive/MyDrive/Papers/STS_2025/VERSION2/PSEUDO_LABELS_SIMPLE\"\n","    data_root = \"/content/drive/MyDrive/Papers/STS_2025/VERSION2/DATASET\"\n","\n","    # Test pseudo-labels\n","    print(\"Testing pseudo-label quality...\")\n","    assessment = test_and_improve_pseudo_labels(\n","        pseudo_labels_dir,\n","        data_root,\n","        apply_additional_icp=True\n","    )\n","\n","    if assessment['use_for_training']:\n","        print(\"\\n✓ Pseudo-labels are ready for training!\")\n","    else:\n","        print(\"\\n⚠ Consider generating better pseudo-labels before training\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WQV0hswsRL-J","executionInfo":{"status":"ok","timestamp":1758542285012,"user_tz":-330,"elapsed":323444,"user":{"displayName":"Gadha Lekshmi P","userId":"03692891214075285585"}},"outputId":"b3ed5d2a-7173-4665-8623-8720d3e2b3e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing pseudo-label quality...\n","Testing 288 pseudo-labels...\n"]},{"output_type":"stream","name":"stderr","text":["Testing pseudo-labels: 100%|██████████| 20/20 [05:23<00:00, 16.16s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Pseudo-Label Quality Assessment (first 20 cases):\n","GOOD: 20/20\n","FAIR: 0/20\n","POOR: 0/20\n","Average improvement: 80.2mm\n","Average final distance: 58.2mm\n","ICP improved 0 cases\n","\n","Recommendation: PROCEED - Pseudo-labels look reasonable for training\n","\n","✓ Pseudo-labels are ready for training!\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["#pseudo + true Train 2"],"metadata":{"id":"pR7BLST7imPT"}},{"cell_type":"code","source":["\"\"\"\n","Complete STSR 2025 Challenge Implementation\n","Following official GitHub structure with proper data processing,\n","correct model architecture, and evaluation metrics.\n","\"\"\"\n","\n","import os\n","import gc\n","import time\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import open3d as o3d\n","from pathlib import Path\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from scipy.spatial.distance import cdist\n","from scipy.spatial.transform import Rotation\n","import nibabel as nib\n","import json\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# ============================================================================\n","# OFFICIAL STSR DATA PROCESSING (from GitHub)\n","# ============================================================================\n","class STSRDataset(Dataset):\n","    \"\"\"STSR dataset following official structure\"\"\"\n","\n","    def __init__(self, root_dir, n_points=2048, mode='train', augment=True):\n","        self.root_dir = Path(root_dir)\n","        self.n_points = n_points\n","        self.mode = mode\n","        self.augment = augment\n","\n","        # Load data pairs\n","        self.samples = self._load_samples()\n","\n","        # Data augmentation\n","        if augment:\n","            self.transform = RandomRigidTransform(mag_trans=0.1, mag_rot=15)\n","        else:\n","            self.transform = None\n","\n","    def _load_samples(self):\n","        samples = []\n","\n","        if self.mode == 'train':\n","            images_dir = self.root_dir / \"Initial_Train_65\" / \"Images\"\n","            labels_dir = self.root_dir / \"Initial_Train_65\" / \"Labels\"\n","        elif self.mode == 'val':\n","            images_dir = self.root_dir / \"Final_Validation_15\" / \"Images\"\n","            labels_dir = self.root_dir / \"Final_Validation_15\" / \"Labels\"\n","        else:  # test\n","            images_dir = self.root_dir / \"Unlabeled_300\" / \"Images\"\n","            labels_dir = None\n","\n","        if not images_dir.exists():\n","            print(f\"Warning: {images_dir} does not exist\")\n","            return samples\n","\n","        for case_dir in images_dir.iterdir():\n","            if case_dir.is_dir():\n","                case_id = case_dir.name\n","\n","                cbct_path = case_dir / \"CBCT.nii.gz\"\n","                upper_stl = case_dir / \"upper.stl\"\n","                lower_stl = case_dir / \"lower.stl\"\n","\n","                if not cbct_path.exists():\n","                    print(f\"Warning: CBCT file not found for case {case_id}\")\n","                    continue\n","\n","                sample = {\n","                    'case_id': case_id,\n","                    'cbct_path': cbct_path,\n","                    'upper_stl_path': upper_stl if upper_stl.exists() else None,\n","                    'lower_stl_path': lower_stl if lower_stl.exists() else None,\n","                }\n","\n","                # Add ground truth if available\n","                if labels_dir and (labels_dir / case_id).exists():\n","                    upper_gt = labels_dir / case_id / \"upper_gt.npy\"\n","                    lower_gt = labels_dir / case_id / \"lower_gt.npy\"\n","\n","                    if upper_gt.exists():\n","                        sample['upper_gt_path'] = upper_gt\n","                    if lower_gt.exists():\n","                        sample['lower_gt_path'] = lower_gt\n","\n","                samples.append(sample)\n","\n","        print(f\"Loaded {len(samples)} samples for {self.mode}\")\n","        return samples\n","\n","    def extract_cbct_points(self, cbct_path, threshold=800, max_points=50000):\n","        \"\"\"FIXED: Use 800 HU threshold as per GitHub dataset.py\"\"\"\n","        try:\n","            if not cbct_path.exists():\n","                print(f\"Warning: CBCT file does not exist: {cbct_path}\")\n","                return np.zeros((1000, 3), dtype=np.float32)\n","\n","            cbct_img = nib.load(str(cbct_path))\n","            cbct_data = cbct_img.get_fdata()\n","\n","            # FIXED: 800 HU threshold (was 500)\n","            points_voxel = np.argwhere(cbct_data > threshold)\n","\n","            if len(points_voxel) == 0:\n","                return np.zeros((1000, 3), dtype=np.float32)\n","\n","            # Convert to world coordinates\n","            points_h = np.hstack([points_voxel[:, [2, 1, 0]], np.ones((points_voxel.shape[0], 1))])\n","            points_world = (cbct_img.affine @ points_h.T).T[:, :3]\n","\n","            # FIXED: Proper subsampling\n","            if len(points_world) > max_points:\n","                indices = np.random.choice(len(points_world), max_points, replace=False)\n","                points_world = points_world[indices]\n","\n","            return points_world.astype(np.float32)\n","\n","        except Exception as e:\n","            print(f\"Error extracting CBCT: {e}\")\n","            return np.zeros((1000, 3), dtype=np.float32)\n","    def extract_stl_points(self, stl_path, max_points=50000):\n","        \"\"\"Extract points from STL mesh\"\"\"\n","        try:\n","            if stl_path is None or not stl_path.exists():\n","                return np.zeros((1000, 3), dtype=np.float32)\n","\n","            mesh = o3d.io.read_triangle_mesh(str(stl_path))\n","\n","            if len(mesh.triangles) == 0 or len(mesh.vertices) == 0:\n","                return np.zeros((1000, 3), dtype=np.float32)\n","\n","            # Use vertices directly (official approach)\n","            points = np.asarray(mesh.vertices)\n","\n","            # Subsample if too many points\n","            if len(points) > max_points:\n","                indices = np.random.choice(len(points), max_points, replace=False)\n","                points = points[indices]\n","\n","            return points.astype(np.float32)\n","\n","        except Exception as e:\n","            print(f\"Error extracting STL: {e}\")\n","            return np.zeros((1000, 3), dtype=np.float32)\n","\n","    def sample_points(self, points, n_target):\n","        \"\"\"Sample points to target number\"\"\"\n","        if len(points) == 0:\n","            return np.zeros((n_target, 3), dtype=np.float32)\n","\n","        if len(points) >= n_target:\n","            indices = np.random.choice(len(points), n_target, replace=False)\n","            return points[indices]\n","        else:\n","            indices = np.random.choice(len(points), n_target, replace=True)\n","            return points[indices]\n","\n","    def __getitem__(self, idx):\n","        \"\"\"FIXED: Proper normalization instead of center alignment\"\"\"\n","        sample = self.samples[idx]\n","\n","        # Extract with official parameters\n","        cbct_points = self.extract_cbct_points(sample['cbct_path'], threshold=800, max_points=50000)\n","        upper_points = self.extract_stl_points(sample['upper_stl_path'], max_points=50000)\n","        lower_points = self.extract_stl_points(sample['lower_stl_path'], max_points=50000)\n","\n","        # Combine STL points\n","        if len(upper_points) > 0 and len(lower_points) > 0:\n","            stl_points = np.vstack([upper_points, lower_points])\n","        elif len(upper_points) > 0:\n","            stl_points = upper_points\n","        elif len(lower_points) > 0:\n","            stl_points = lower_points\n","        else:\n","            stl_points = np.zeros((1000, 3), dtype=np.float32)\n","\n","        # Apply ground truth transformation\n","        target_points = stl_points.copy()\n","        gt_transform = np.eye(4, dtype=np.float32)\n","\n","        # Safe ground truth loading\n","        upper_gt_exists = ('upper_gt_path' in sample and\n","                          sample['upper_gt_path'] is not None and\n","                          sample['upper_gt_path'].exists())\n","\n","        if upper_gt_exists and len(upper_points) > 0:\n","            try:\n","                upper_gt = np.load(sample['upper_gt_path'])\n","                upper_h = np.hstack([upper_points, np.ones((len(upper_points), 1))])\n","                upper_transformed = (upper_gt @ upper_h.T).T[:, :3]\n","\n","                lower_gt_exists = ('lower_gt_path' in sample and\n","                                  sample['lower_gt_path'] is not None and\n","                                  sample['lower_gt_path'].exists())\n","\n","                if lower_gt_exists and len(lower_points) > 0:\n","                    try:\n","                        lower_gt = np.load(sample['lower_gt_path'])\n","                        lower_h = np.hstack([lower_points, np.ones((len(lower_points), 1))])\n","                        lower_transformed = (lower_gt @ lower_h.T).T[:, :3]\n","                        target_points = np.vstack([upper_transformed, lower_transformed])\n","                    except:\n","                        target_points = upper_transformed\n","                else:\n","                    target_points = upper_transformed\n","\n","                gt_transform = upper_gt\n","\n","            except Exception as e:\n","                print(f\"Error loading GT for {sample['case_id']}: {e}\")\n","\n","        # FIXED: Proper normalization following GitHub transforms.py\n","        if len(cbct_points) > 0 and len(stl_points) > 0:\n","            # Global normalization (following GitHub)\n","            all_points = np.vstack([cbct_points, stl_points])\n","            center = np.mean(all_points, axis=0)\n","            scale = np.max(np.linalg.norm(all_points - center, axis=1))\n","\n","            if scale > 0:\n","                cbct_norm = (cbct_points - center) / scale\n","                stl_norm = (stl_points - center) / scale\n","                target_norm = (target_points - center) / scale\n","            else:\n","                cbct_norm = cbct_points - center\n","                stl_norm = stl_points - center\n","                target_norm = target_points - center\n","            norm_center = torch.from_numpy(center).float()\n","            norm_scale = torch.tensor(scale).float()\n","        else:\n","            cbct_norm = cbct_points\n","            stl_norm = stl_points\n","            target_norm = target_points\n","            norm_center = torch.zeros(3).float()\n","            norm_scale = torch.tensor(1.0).float()\n","\n","        # Apply data augmentation if enabled\n","        if self.transform is not None and self.mode == 'train':\n","            stl_norm, aug_transform = self.transform(stl_norm)\n","            gt_transform = aug_transform @ gt_transform\n","\n","        # Sample to target size\n","        cbct_sampled = self.sample_points(cbct_norm, self.n_points)\n","        stl_sampled = self.sample_points(stl_norm, self.n_points)\n","        target_sampled = self.sample_points(target_norm, self.n_points)\n","\n","        return {\n","              'cbct': torch.from_numpy(cbct_sampled).float(),\n","              'stl': torch.from_numpy(stl_sampled).float(),\n","              'target': torch.from_numpy(target_sampled).float(),\n","              'gt_transform': torch.from_numpy(gt_transform).float(),\n","              'norm_center': norm_center,  # ADD THIS\n","              'norm_scale': norm_scale,    # ADD THIS\n","              'case_id': sample['case_id']\n","          }\n","\n","    def __len__(self):\n","        return len(self.samples)\n","def compute_aabb(points):\n","    \"\"\"Compute axis-aligned bounding box\"\"\"\n","    min_coords = np.min(points, axis=0)\n","    max_coords = np.max(points, axis=0)\n","    center = (min_coords + max_coords) / 2\n","    return min_coords, max_coords, center\n","\n","def center_align_points(points, center):\n","    \"\"\"Center align points to given center\"\"\"\n","    return points - center\n","\n","class RandomRigidTransform:\n","    \"\"\"Official data augmentation from GitHub\"\"\"\n","    def __init__(self, mag_trans=0.5, mag_rot=45):\n","        self.mag_trans = mag_trans  # Translation magnitude in meters\n","        self.mag_rot = mag_rot      # Rotation magnitude in degrees\n","\n","    def __call__(self, points):\n","        # Random rotation\n","        angle_x = np.random.uniform(-self.mag_rot, self.mag_rot)\n","        angle_y = np.random.uniform(-self.mag_rot, self.mag_rot)\n","        angle_z = np.random.uniform(-self.mag_rot, self.mag_rot)\n","        rotation = Rotation.from_euler('xyz', [angle_x, angle_y, angle_z], degrees=True)\n","        R = rotation.as_matrix()\n","\n","        # Random translation\n","        t = np.random.uniform(-self.mag_trans, self.mag_trans, size=3)\n","\n","        # Build 4x4 transformation matrix\n","        transform = np.identity(4)\n","        transform[:3, :3] = R\n","        transform[:3, 3] = t\n","\n","        # Apply transformation\n","        points_homogeneous = np.hstack([points, np.ones((points.shape[0], 1))])\n","        transformed_points = (transform @ points_homogeneous.T).T[:, :3]\n","\n","        return transformed_points, transform\n","\n","# ============================================================================\n","# OFFICIAL EVALUATION METRICS (from GitHub)\n","# ============================================================================\n","\n","def compute_rmse(pred_points, gt_points):\n","    \"\"\"Root Mean Square Error\"\"\"\n","    return np.sqrt(np.mean((pred_points - gt_points) ** 2))\n","\n","def compute_ncc(pred_points, gt_points):\n","    \"\"\"Normalized Cross-Correlation\"\"\"\n","    pred_flat = pred_points.flatten()\n","    gt_flat = gt_points.flatten()\n","\n","    pred_centered = pred_flat - np.mean(pred_flat)\n","    gt_centered = gt_flat - np.mean(gt_flat)\n","\n","    numerator = np.sum(pred_centered * gt_centered)\n","    denominator = np.sqrt(np.sum(pred_centered**2) * np.sum(gt_centered**2))\n","\n","    return numerator / (denominator + 1e-8)\n","\n","def compute_nmi(pred_points, gt_points, bins=50):\n","    \"\"\"Normalized Mutual Information\"\"\"\n","    from sklearn.metrics import normalized_mutual_info_score\n","\n","    pred_flat = pred_points.flatten()\n","    gt_flat = gt_points.flatten()\n","\n","    # Normalize to [0, 1]\n","    pred_norm = (pred_flat - pred_flat.min()) / (pred_flat.max() - pred_flat.min() + 1e-8)\n","    gt_norm = (gt_flat - gt_flat.min()) / (gt_flat.max() - gt_flat.min() + 1e-8)\n","\n","    # Discretize\n","    pred_discrete = np.floor(pred_norm * (bins - 1)).astype(int)\n","    gt_discrete = np.floor(gt_norm * (bins - 1)).astype(int)\n","\n","    return normalized_mutual_info_score(pred_discrete, gt_discrete)\n","\n","def surface_dice(pred_points, gt_points, tolerance=1.0):\n","    \"\"\"Surface Dice coefficient (from SurfaceDice.py)\"\"\"\n","    # Find correspondences within tolerance\n","    distances = cdist(pred_points, gt_points)\n","\n","    # Points in pred that are close to gt\n","    pred_close = np.any(distances <= tolerance, axis=1)\n","\n","    # Points in gt that are close to pred\n","    gt_close = np.any(distances <= tolerance, axis=0)\n","\n","    intersection = np.sum(pred_close) + np.sum(gt_close)\n","    union = len(pred_points) + len(gt_points)\n","\n","    return intersection / union if union > 0 else 0.0\n","\n","class STSROfficialEvaluator:\n","    \"\"\"Official STSR evaluation metrics\"\"\"\n","\n","    def __init__(self):\n","        self.metrics = {}\n","\n","    def evaluate_registration(self, pred_stl, gt_stl, pred_transform=None, gt_transform=None):\n","        \"\"\"Complete evaluation with all official metrics\"\"\"\n","        metrics = {}\n","\n","        try:\n","            # Convert tensors if needed\n","            if torch.is_tensor(pred_stl):\n","                pred_stl = pred_stl.detach().cpu().numpy()\n","            if torch.is_tensor(gt_stl):\n","                gt_stl = gt_stl.detach().cpu().numpy()\n","\n","            # Handle batch dimension\n","            if len(pred_stl.shape) == 3:\n","                pred_stl = pred_stl.reshape(-1, 3)\n","            if len(gt_stl.shape) == 3:\n","                gt_stl = gt_stl.reshape(-1, 3)\n","\n","            # Check for valid data\n","            if len(pred_stl) == 0 or len(gt_stl) == 0:\n","                return self._default_metrics()\n","\n","            # Official metrics with error handling\n","            try:\n","                metrics['rmse'] = float(compute_rmse(pred_stl, gt_stl))\n","            except:\n","                metrics['rmse'] = 0.0\n","\n","            try:\n","                metrics['ncc'] = float(compute_ncc(pred_stl, gt_stl))\n","            except:\n","                metrics['ncc'] = 0.0\n","\n","            try:\n","                metrics['nmi'] = float(compute_nmi(pred_stl, gt_stl))\n","            except:\n","                metrics['nmi'] = 0.0\n","\n","            try:\n","                metrics['surface_dice'] = float(surface_dice(pred_stl, gt_stl))\n","            except:\n","                metrics['surface_dice'] = 0.0\n","\n","            # Chamfer distance\n","            try:\n","                dist1 = np.min(cdist(pred_stl, gt_stl), axis=1)\n","                dist2 = np.min(cdist(gt_stl, pred_stl), axis=1)\n","                metrics['chamfer_distance'] = float(np.mean(dist1) + np.mean(dist2))\n","            except:\n","                metrics['chamfer_distance'] = 0.0\n","\n","            # Transformation metrics with robust error handling\n","            if pred_transform is not None and gt_transform is not None:\n","                try:\n","                    # Convert to numpy\n","                    if torch.is_tensor(pred_transform):\n","                        pred_transform = pred_transform.detach().cpu().numpy()\n","                    if torch.is_tensor(gt_transform):\n","                        gt_transform = gt_transform.detach().cpu().numpy()\n","\n","                    # Handle different input shapes\n","                    if len(pred_transform.shape) == 3:  # Batch dimension\n","                        pred_T = pred_transform[0]\n","                        gt_T = gt_transform[0]\n","                    else:  # Single matrix\n","                        pred_T = pred_transform\n","                        gt_T = gt_transform\n","\n","                    # Ensure 4x4 matrices\n","                    if pred_T.shape == (4, 4) and gt_T.shape == (4, 4):\n","                        # Translation error\n","                        pred_trans = pred_T[:3, 3]\n","                        gt_trans = gt_T[:3, 3]\n","                        metrics['translation_error'] = float(np.linalg.norm(pred_trans - gt_trans))\n","\n","                        # Rotation error\n","                        pred_rot = pred_T[:3, :3]\n","                        gt_rot = gt_T[:3, :3]\n","\n","                        # Ensure valid rotation matrices\n","                        if (np.allclose(np.linalg.det(pred_rot), 1, atol=0.1) and\n","                            np.allclose(np.linalg.det(gt_rot), 1, atol=0.1)):\n","\n","                            rot_diff = pred_rot @ gt_rot.T\n","                            trace = np.trace(rot_diff)\n","\n","                            # Clamp trace for numerical stability\n","                            trace = np.clip(trace, -1, 3)\n","                            angle = np.arccos(np.clip((trace - 1) / 2, -1, 1))\n","                            metrics['rotation_error_degrees'] = float(np.degrees(angle))\n","                        else:\n","                            metrics['rotation_error_degrees'] = 0.0\n","                    else:\n","                        metrics['translation_error'] = 0.0\n","                        metrics['rotation_error_degrees'] = 0.0\n","\n","                except Exception as e:\n","                    print(f\"Warning: Transform metrics failed: {e}\")\n","                    metrics['translation_error'] = 0.0\n","                    metrics['rotation_error_degrees'] = 0.0\n","            else:\n","                metrics['translation_error'] = 0.0\n","                metrics['rotation_error_degrees'] = 0.0\n","\n","        except Exception as e:\n","            print(f\"Warning: Evaluation failed: {e}\")\n","            return self._default_metrics()\n","\n","        return metrics\n","\n","    def _default_metrics(self):\n","        \"\"\"Return default metrics when evaluation fails\"\"\"\n","        return {\n","            'rmse': 0.0,\n","            'ncc': 0.0,\n","            'nmi': 0.0,\n","            'surface_dice': 0.0,\n","            'chamfer_distance': 0.0,\n","            'translation_error': 0.0,\n","            'rotation_error_degrees': 0.0\n","        }\n","\n","\n","\n","class PointNetFeatureExtractor(nn.Module):\n","    \"\"\"PointNet feature extractor for point clouds\"\"\"\n","\n","    def __init__(self, input_dim=3, feature_dim=1024):\n","        super().__init__()\n","\n","        self.conv1 = nn.Conv1d(input_dim, 64, 1)\n","        self.conv2 = nn.Conv1d(64, 128, 1)\n","        self.conv3 = nn.Conv1d(128, feature_dim, 1)\n","\n","        self.bn1 = nn.BatchNorm1d(64)\n","        self.bn2 = nn.BatchNorm1d(128)\n","        self.bn3 = nn.BatchNorm1d(feature_dim)\n","\n","        self.dropout = nn.Dropout(0.3)\n","\n","    def forward(self, x):\n","        # x: [B, N, 3] -> [B, 3, N]\n","        x = x.transpose(2, 1)\n","\n","        x = torch.relu(self.bn1(self.conv1(x)))\n","        x = torch.relu(self.bn2(self.conv2(x)))\n","        x = self.bn3(self.conv3(x))\n","\n","        # Global max pooling\n","        x = torch.max(x, 2, keepdim=True)[0]\n","        x = x.view(-1, x.size(1))\n","\n","        return self.dropout(x)\n","\n","class PointNetLK(nn.Module):\n","    \"\"\"PointNetLK registration model\"\"\"\n","\n","    def __init__(self, feature_extractor, num_iterations=10, feature_dim=1024):\n","        super().__init__()\n","        self.feature_extractor = feature_extractor\n","        self.num_iterations = num_iterations\n","\n","        # THIS WAS MISSING - Add the update network\n","        self.update_net = nn.Sequential(\n","            nn.Linear(feature_dim, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(512, 256),\n","            nn.BatchNorm1d(256),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(256, 6)  # 6-DOF transformation parameters\n","        )\n","\n","    def forward(self, source, target):\n","        B = source.shape[0]\n","        device = source.device\n","\n","        # Initialize transformation as identity\n","        T = torch.eye(4, device=device, dtype=source.dtype).unsqueeze(0).repeat(B, 1, 1)\n","\n","        # Extract target features ONCE (template)\n","        f_t = self.feature_extractor(target)\n","\n","        for i in range(self.num_iterations):\n","            # Apply current transformation to source\n","            source_transformed = self.apply_transform(source, T)\n","\n","            # Extract features from transformed source\n","            f_s = self.feature_extractor(source_transformed)\n","\n","            # Compute feature DIFFERENCE (Lucas-Kanade approach)\n","            feature_diff = f_t - f_s  # This is the error signal\n","\n","            # Predict incremental update\n","            update_params = self.update_net(feature_diff)\n","\n","            # Convert to transformation matrix\n","            delta_T = self.params_to_transform(update_params)\n","\n","            # Update transformation\n","            T = torch.bmm(delta_T, T)\n","\n","        return T\n","\n","    def apply_transform(self, points, T):\n","        \"\"\"Apply transformation matrix to points\"\"\"\n","        B, N, _ = points.shape\n","        ones = torch.ones(B, N, 1, device=points.device, dtype=points.dtype)\n","        points_h = torch.cat([points, ones], dim=2)\n","        transformed = torch.bmm(T, points_h.transpose(1, 2)).transpose(1, 2)\n","        return transformed[:, :, :3]\n","\n","    def params_to_transform(self, params):\n","        \"\"\"Convert 6-DOF parameters to 4x4 transformation matrix\"\"\"\n","        B = params.shape[0]\n","        device = params.device\n","\n","        # Split into translation and rotation parameters\n","        translation = params[:, :3]\n","        rotation_params = params[:, 3:]\n","\n","        # Convert rotation parameters to rotation matrix\n","        angle = torch.norm(rotation_params, dim=1, keepdim=True)\n","        axis = rotation_params / (angle + 1e-8)\n","\n","        # Rodrigues' rotation formula\n","        K = torch.zeros(B, 3, 3, device=device)\n","        K[:, 0, 1] = -axis[:, 2]\n","        K[:, 0, 2] = axis[:, 1]\n","        K[:, 1, 0] = axis[:, 2]\n","        K[:, 1, 2] = -axis[:, 0]\n","        K[:, 2, 0] = -axis[:, 1]\n","        K[:, 2, 1] = axis[:, 0]\n","\n","        I = torch.eye(3, device=device).unsqueeze(0).repeat(B, 1, 1)\n","        R = I + torch.sin(angle).unsqueeze(-1) * K + (1 - torch.cos(angle).unsqueeze(-1)) * torch.bmm(K, K)\n","\n","        # Build 4x4 transformation matrix\n","        T = torch.eye(4, device=device).unsqueeze(0).repeat(B, 1, 1)\n","        T[:, :3, :3] = R\n","        T[:, :3, 3] = translation\n","\n","        return T\n","\n","# ADD this to STSRModel:\n","class STSRModel(nn.Module):\n","    def __init__(self, feature_dim=1024, num_iterations=10):\n","        super().__init__()\n","\n","        self.feature_extractor = PointNetFeatureExtractor(3, feature_dim)\n","        self.pointnetlk = PointNetLK(self.feature_extractor, num_iterations, feature_dim)\n","\n","        # ADD: Separate heads for upper/lower if needed\n","        self.upper_head = nn.Linear(feature_dim, 6)\n","        self.lower_head = nn.Linear(feature_dim, 6)\n","\n","    def forward(self, cbct, stl, jaw_type=None):\n","        if jaw_type is not None:\n","            # Handle upper/lower separately\n","            pass\n","        else:\n","            # Current combined approach\n","            return self.pointnetlk(stl, cbct)  # FIXED: swapped order\n","\n","\n","\n","\n","# ============================================================================\n","# TRAINING PIPELINE\n","# ============================================================================\n","\n","class STSRTrainer:\n","    def __init__(self, model, device, save_dir):\n","        self.model = model\n","        self.device = device\n","        self.save_dir = Path(save_dir)\n","        self.save_dir.mkdir(parents=True, exist_ok=True)\n","\n","        self.evaluator = STSROfficialEvaluator()\n","        self.history = {\n","              'train_loss': [], 'val_loss': [],\n","              'train_chamfer': [], 'val_chamfer': [],  # Add these\n","              'train_transform': [], 'val_transform': [],  # Add these\n","              'rmse': [], 'ncc': [], 'nmi': [], 'surface_dice': [],\n","              'chamfer_distance': [],\n","              'translation_error': [],\n","              'rotation_error_degrees': [],\n","              'mean_translation_error_mm': [],\n","              'mean_rotation_error_deg': []\n","          }\n","\n","    def chamfer_loss(self, pred, target):\n","        \"\"\"Chamfer distance loss\"\"\"\n","        # pred, target: [B, N, 3]\n","        dist1 = torch.cdist(pred, target)  # [B, N, N]\n","        dist2 = torch.cdist(target, pred)  # [B, N, N]\n","\n","        cd1 = torch.mean(torch.min(dist1, dim=2)[0], dim=1)  # [B]\n","        cd2 = torch.mean(torch.min(dist2, dim=2)[0], dim=1)  # [B]\n","\n","        return torch.mean(cd1 + cd2)\n","    def normalize_gt_transform(self, gt_transform, center, scale):\n","        \"\"\"Transform GT matrix from raw coordinates to normalized space\"\"\"\n","        # gt_transform: [B, 4, 4] - transforms from raw STL to raw target\n","        # We need: normalized STL to normalized target\n","\n","        B = gt_transform.shape[0]\n","        device = gt_transform.device\n","\n","        # Create normalization matrices\n","        # S = scale matrix, T = translation matrix\n","        S_inv = torch.eye(4, device=device).unsqueeze(0).repeat(B, 1, 1)\n","        S_inv[:, :3, :3] = torch.eye(3, device=device) / scale.unsqueeze(-1).unsqueeze(-1)\n","        S_inv[:, :3, 3] = -center / scale.unsqueeze(-1)\n","\n","        S = torch.eye(4, device=device).unsqueeze(0).repeat(B, 1, 1)\n","        S[:, :3, :3] = torch.eye(3, device=device) * scale.unsqueeze(-1).unsqueeze(-1)\n","        S[:, :3, 3] = center\n","\n","        # Transform: normalized = S_inv * raw * S\n","        normalized_gt = torch.bmm(torch.bmm(S_inv, gt_transform), S)\n","\n","        return normalized_gt\n","    def combined_loss(self, predicted_stl, target_stl, pred_transform, gt_transform, norm_center, norm_scale):\n","        \"\"\"Combined loss with normalized GT transforms\"\"\"\n","\n","        # Normalize GT transform to match predicted transform coordinate system\n","        gt_transform_norm = self.normalize_gt_transform(gt_transform, norm_center, norm_scale)\n","\n","        # Chamfer loss (point alignment)\n","        chamfer = self.chamfer_loss(predicted_stl, target_stl)\n","\n","        # Transform loss (direct supervision in normalized space)\n","        trans_error = torch.mean(torch.norm(\n","            pred_transform[:, :3, 3] - gt_transform_norm[:, :3, 3], dim=1\n","        ))\n","\n","        rot_error = torch.mean(torch.norm(\n","            pred_transform[:, :3, :3] - gt_transform_norm[:, :3, :3], dim=(1,2)\n","        ))\n","\n","        transform_loss = trans_error + rot_error * 0.1\n","\n","        total_loss = chamfer + transform_loss\n","        return total_loss, chamfer, transform_loss\n","    def train_epoch(self, train_loader, optimizer):\n","        self.model.train()\n","        total_loss = 0\n","        num_batches = 0\n","\n","        pbar = tqdm(train_loader, desc=\"Training\")\n","        for batch in pbar:\n","            cbct = batch['cbct'].to(self.device)\n","            stl = batch['stl'].to(self.device)\n","            target = batch['target'].to(self.device)\n","            gt_transform = batch['gt_transform'].to(self.device)  # ADD THIS LINE\n","            norm_center = batch['norm_center'].to(self.device)    # ADD THIS LINE\n","            norm_scale = batch['norm_scale'].to(self.device)      # ADD THIS LINE\n","\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            predicted_transform = self.model(cbct, stl)\n","\n","            # Apply predicted transformation\n","            stl_h = torch.cat([stl, torch.ones(stl.shape[0], stl.shape[1], 1, device=self.device)], dim=2)\n","            predicted_stl = torch.bmm(predicted_transform, stl_h.transpose(1, 2)).transpose(1, 2)[:, :, :3]\n","\n","            # Compute combined loss\n","            total_loss_val, chamfer_loss_val, transform_loss_val = self.combined_loss(\n","                predicted_stl, target, predicted_transform, gt_transform, norm_center, norm_scale\n","            )\n","\n","            total_loss_val.backward()\n","            optimizer.step()\n","\n","            total_loss += total_loss_val.item()\n","            num_batches += 1\n","\n","            pbar.set_postfix({\n","                'Loss': f\"{total_loss_val.item():.4f}\",\n","                'Chamfer': f\"{chamfer_loss_val.item():.4f}\",\n","                'Transform': f\"{transform_loss_val.item():.4f}\"\n","            })\n","\n","        return total_loss / num_batches\n","    def validate_epoch(self, val_loader):\n","        self.model.eval()\n","        total_loss = 0\n","        all_metrics = []\n","\n","        with torch.no_grad():\n","            pbar = tqdm(val_loader, desc=\"Validation\")\n","            for batch in pbar:\n","                cbct = batch['cbct'].to(self.device)\n","                stl = batch['stl'].to(self.device)\n","                target = batch['target'].to(self.device)\n","                gt_transform = batch['gt_transform'].to(self.device)   # MOVED TO GPU\n","                norm_center = batch['norm_center'].to(self.device)    # ADD THIS LINE\n","                norm_scale = batch['norm_scale'].to(self.device)      # ADD THIS LINE\n","                # Forward pass\n","                predicted_transform = self.model(stl, cbct)\n","\n","                # Apply predicted transformation\n","                stl_h = torch.cat([stl, torch.ones(stl.shape[0], stl.shape[1], 1, device=self.device)], dim=2)\n","                predicted_stl = torch.bmm(predicted_transform, stl_h.transpose(1, 2)).transpose(1, 2)[:, :, :3]\n","\n","                # Compute loss\n","                total_loss_val, chamfer_loss_val, transform_loss_val = self.combined_loss(\n","                  predicted_stl, target, predicted_transform, gt_transform, norm_center, norm_scale\n","                  )\n","                total_loss += total_loss_val.item()\n","\n","                # Compute official metrics for each sample in batch\n","                for i in range(predicted_stl.shape[0]):\n","                    metrics = self.evaluator.evaluate_registration(\n","                        predicted_stl[i], target[i],\n","                        predicted_transform[i], gt_transform[i]  # PASS TRANSFORMS\n","                    )\n","                    all_metrics.append(metrics)\n","\n","                pbar.set_postfix({\n","                    'Loss': f\"{total_loss_val.item():.4f}\",\n","                    'Chamfer': f\"{chamfer_loss_val.item():.4f}\",\n","                    'Transform': f\"{transform_loss_val.item():.4f}\"\n","                })\n","\n","        # Average metrics\n","        avg_metrics = {}\n","        for key in all_metrics[0].keys():\n","            values = [m[key] for m in all_metrics if m[key] is not None]\n","            avg_metrics[key] = np.mean(values) if values else 0.0\n","\n","        # Add mean metrics for STSR evaluation\n","        avg_metrics['mean_translation_error_mm'] = avg_metrics.get('translation_error', 0.0)\n","        avg_metrics['mean_rotation_error_deg'] = avg_metrics.get('rotation_error_degrees', 0.0)\n","\n","        return total_loss / len(val_loader), avg_metrics\n","\n","    def train(self, train_loader, val_loader, num_epochs, lr=1e-4):\n","        optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=1e-4)\n","        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n","\n","        best_loss = float('inf')\n","        patience = 10           # EARLY STOPPING: wait 10 epochs\n","        patience_counter = 0    # EARLY STOPPING: counter\n","\n","        for epoch in range(num_epochs):\n","            print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n","\n","            # Train\n","            train_loss = self.train_epoch(train_loader, optimizer)\n","\n","            # Validate\n","            val_loss, val_metrics = self.validate_epoch(val_loader)\n","\n","            # Update scheduler\n","            scheduler.step(val_loss)\n","\n","            # Store history safely\n","            self.history['train_loss'].append(train_loss)\n","            self.history['val_loss'].append(val_loss)\n","\n","            if val_metrics:\n","                for key, value in val_metrics.items():\n","                    if key in self.history and value is not None:\n","                        try:\n","                            self.history[key].append(float(value))\n","                        except (ValueError, TypeError):\n","                            print(f\"Warning: Could not convert {key}={value} to float\")\n","\n","            # Print metrics safely\n","            print(f\"Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}\")\n","\n","            if val_metrics:\n","                print(f\"RMSE: {val_metrics.get('rmse', 'N/A'):.4f} | \"\n","                      f\"Translation: {val_metrics.get('translation_error', 'N/A'):.4f}mm | \"\n","                      f\"Rotation: {val_metrics.get('rotation_error_degrees', 'N/A'):.2f}°\")\n","                print(f\"Surface Dice: {val_metrics.get('surface_dice', 'N/A'):.4f} | \"\n","                      f\"Chamfer: {val_metrics.get('chamfer_distance', 'N/A'):.4f}\")\n","\n","            # Early stopping logic\n","            if val_loss < best_loss:\n","                best_loss = val_loss\n","                patience_counter = 0\n","\n","                # Save best model\n","                torch.save({\n","                    'epoch': epoch,\n","                    'model_state_dict': self.model.state_dict(),\n","                    'optimizer_state_dict': optimizer.state_dict(),\n","                    'best_val_loss': best_loss,\n","                    'history': self.history\n","                }, self.save_dir / 'best_model.pth')\n","\n","                torch.save(self.model.state_dict(), self.save_dir / 'best_model_state_dict.pth')\n","                print(f\"✓ Best model saved: {val_loss:.6f}\")\n","            else:\n","                patience_counter += 1\n","                print(f\"No improvement for {patience_counter}/{patience} epochs\")\n","\n","                if patience_counter >= patience:\n","                    print(f\"Early stopping triggered after {epoch+1} epochs\")\n","                    break\n","\n","        # Save final model\n","        torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': self.model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'final_train_loss': train_loss,\n","            'final_val_loss': val_loss,\n","            'best_val_loss': best_loss,\n","            'complete_history': self.history\n","        }, self.save_dir / 'final_model.pth')\n","\n","        torch.save(self.model.state_dict(), self.save_dir / 'final_model_state_dict.pth')\n","        print(f\"✓ Final model saved\")\n","\n","        self.plot_training_curves()\n","        return self.history\n","\n","    def plot_training_curves(self):\n","        \"\"\"FIXED: Handle missing data gracefully\"\"\"\n","        try:\n","            fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n","            fig.suptitle('STSR 2025 Training Progress - All Official Metrics', fontsize=16, fontweight='bold')\n","\n","            # Loss curves\n","            if self.history['train_loss'] and self.history['val_loss']:\n","                axes[0, 0].plot(self.history['train_loss'], label='Train Loss', linewidth=2)\n","                axes[0, 0].plot(self.history['val_loss'], label='Val Loss', linewidth=2)\n","                axes[0, 0].set_title('Training Loss', fontweight='bold')\n","                axes[0, 0].set_xlabel('Epoch')\n","                axes[0, 0].set_ylabel('Loss')\n","                axes[0, 0].legend()\n","                axes[0, 0].grid(True, alpha=0.3)\n","\n","            # FIXED: Safe plotting with existence checks\n","            metrics_to_plot = [\n","                ('rmse', 'RMSE (Official Metric)', 'red', (0, 1)),\n","                ('ncc', 'Normalized Cross-Correlation', 'green', (0, 2)),\n","                ('nmi', 'Normalized Mutual Information', 'blue', (1, 0)),\n","                ('surface_dice', 'Surface Dice Coefficient', 'purple', (1, 1)),\n","                ('chamfer_distance', 'Chamfer Distance', 'orange', (1, 2)),\n","                ('translation_error', 'Translation Error (mm)', 'brown', (2, 0)),\n","                ('rotation_error_degrees', 'Rotation Error (degrees)', 'pink', (2, 1))\n","            ]\n","\n","            for metric, title, color, pos in metrics_to_plot:\n","                if metric in self.history and self.history[metric] and len(self.history[metric]) > 0:\n","                    axes[pos].plot(self.history[metric], color=color, linewidth=2)\n","                    axes[pos].set_title(title, fontweight='bold')\n","                    axes[pos].set_xlabel('Epoch')\n","                    axes[pos].set_ylabel(metric.replace('_', ' ').title())\n","                    axes[pos].grid(True, alpha=0.3)\n","                else:\n","                    axes[pos].text(0.5, 0.5, f'No {metric} data', ha='center', va='center',\n","                                transform=axes[pos].transAxes)\n","                    axes[pos].set_title(title, fontweight='bold')\n","\n","            # Model info\n","            axes[2, 2].text(0.5, 0.5,\n","                          'STSR 2025 Model:\\n\\n'\n","                          '• PointNet Feature Extraction\\n'\n","                          '• PointNetLK Registration\\n'\n","                          '• Lucas-Kanade Optimization\\n'\n","                          '• Official STSR Evaluation\\n'\n","                          '• 800 HU CBCT Threshold\\n'\n","                          '• GitHub Standard Processing',\n","                          ha='center', va='center', transform=axes[2, 2].transAxes,\n","                          fontsize=11, bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n","            axes[2, 2].set_title('Model Architecture', fontweight='bold')\n","            axes[2, 2].axis('off')\n","\n","            plt.tight_layout()\n","            plt.savefig(self.save_dir / 'training_curves_complete.png', dpi=300, bbox_inches='tight')\n","            plt.close()\n","\n","            print(f\"✓ Training curves saved to: {self.save_dir / 'training_curves_complete.png'}\")\n","\n","        except Exception as e:\n","            print(f\"Warning: Could not generate training curves: {e}\")\n","\n","# ============================================================================\n","# INFERENCE AND SUBMISSION\n","# ============================================================================\n","\n","def generate_submission(model, test_loader, output_dir):\n","    \"\"\"Generate submission file with predictions\"\"\"\n","    model.eval()\n","    output_dir = Path(output_dir)\n","    output_dir.mkdir(parents=True, exist_ok=True)\n","\n","    predictions = {}\n","\n","    with torch.no_grad():\n","        for batch in tqdm(test_loader, desc=\"Generating predictions\"):\n","            cbct = batch['cbct'].to(next(model.parameters()).device)\n","            stl = batch['stl'].to(next(model.parameters()).device)\n","            case_ids = batch['case_id']\n","\n","            # Predict transformations\n","            predicted_transforms = model(stl, cbct)\n","\n","            # Save predictions\n","            for i, case_id in enumerate(case_ids):\n","                case_dir = output_dir / case_id\n","                case_dir.mkdir(exist_ok=True)\n","\n","                transform = predicted_transforms[i].cpu().numpy()\n","\n","                # Save both upper and lower transformations\n","                # (In practice, you might want separate predictions)\n","                np.save(case_dir / \"upper_gt.npy\", transform)\n","                np.save(case_dir / \"lower_gt.npy\", transform)\n","\n","                predictions[case_id] = transform\n","\n","    # Create submission zip\n","    import zipfile\n","    zip_path = output_dir / \"submission.zip\"\n","    with zipfile.ZipFile(zip_path, 'w') as zipf:\n","        for case_dir in output_dir.iterdir():\n","            if case_dir.is_dir() and case_dir.name != '__pycache__':\n","                for file in case_dir.glob(\"*_gt.npy\"):\n","                    arcname = f\"{case_dir.name}/{file.name}\"\n","                    zipf.write(file, arcname)\n","\n","    print(f\"Submission saved to: {zip_path}\")\n","    return predictions\n","\n","class STSRSemiSupervisedDataset(Dataset):\n","    \"\"\"Updated dataset that loads both labeled and pseudo-labeled data\"\"\"\n","\n","    def __init__(self, root_dir, pseudo_labels_dir=None, n_points=2048, mode='train',\n","                 augment=True, apply_icp_before_training=False):\n","        self.root_dir = Path(root_dir)\n","        self.pseudo_labels_dir = Path(pseudo_labels_dir) if pseudo_labels_dir else None\n","        self.n_points = n_points\n","        self.mode = mode\n","        self.augment = augment\n","        self.apply_icp_before_training = apply_icp_before_training\n","\n","        # Load samples (both labeled and pseudo-labeled)\n","        self.samples = self._load_samples()\n","\n","        if augment:\n","            self.transform = RandomRigidTransform(mag_trans=0.1, mag_rot=15)\n","        else:\n","            self.transform = None\n","\n","    def _load_samples(self):\n","        samples = []\n","\n","        # 1. Load original labeled data\n","        if self.mode == 'train':\n","            labeled_images_dir = self.root_dir / \"Initial_Train_65\" / \"Images\"\n","            labeled_labels_dir = self.root_dir / \"Initial_Train_65\" / \"Labels\"\n","\n","            if labeled_images_dir.exists():\n","                for case_dir in labeled_images_dir.iterdir():\n","                    if case_dir.is_dir():\n","                        sample = self._create_sample(case_dir, labeled_labels_dir, 'labeled')\n","                        if sample:\n","                            samples.append(sample)\n","\n","            # 2. Load pseudo-labeled data (only in training mode)\n","            if self.pseudo_labels_dir and self.pseudo_labels_dir.exists():\n","                unlabeled_images_dir = self.root_dir / \"Unlabeled_300\" / \"Images\"\n","\n","                # Filter to only cases that have pseudo-labels\n","                valid_pseudo_cases = [d.name for d in self.pseudo_labels_dir.iterdir() if d.is_dir()]\n","\n","                for case_id in valid_pseudo_cases:\n","                    case_dir = unlabeled_images_dir / case_id\n","                    if case_dir.exists():\n","                        sample = self._create_sample(case_dir, self.pseudo_labels_dir, 'pseudo')\n","                        if sample:\n","                            samples.append(sample)\n","\n","        elif self.mode == 'val':\n","            # Validation uses only original labeled data\n","            val_images_dir = self.root_dir / \"Final_Validation_15\" / \"Images\"\n","            val_labels_dir = self.root_dir / \"Final_Validation_15\" / \"Labels\"\n","\n","            if val_images_dir.exists():\n","                for case_dir in val_images_dir.iterdir():\n","                    if case_dir.is_dir():\n","                        sample = self._create_sample(case_dir, val_labels_dir, 'labeled')\n","                        if sample:\n","                            samples.append(sample)\n","\n","        print(f\"Loaded {len(samples)} samples for {self.mode}\")\n","\n","        # Count labeled vs pseudo-labeled\n","        if self.mode == 'train':\n","            labeled_count = sum(1 for s in samples if s['data_type'] == 'labeled')\n","            pseudo_count = sum(1 for s in samples if s['data_type'] == 'pseudo')\n","            print(f\"  - Labeled: {labeled_count}\")\n","            print(f\"  - Pseudo-labeled: {pseudo_count}\")\n","\n","        return samples\n","\n","    def _create_sample(self, case_dir, labels_dir, data_type):\n","        \"\"\"Create a sample dictionary\"\"\"\n","        case_id = case_dir.name\n","\n","        cbct_path = case_dir / \"CBCT.nii.gz\"\n","        upper_stl = case_dir / \"upper.stl\"\n","        lower_stl = case_dir / \"lower.stl\"\n","\n","        if not cbct_path.exists():\n","            return None\n","\n","        sample = {\n","            'case_id': case_id,\n","            'cbct_path': cbct_path,\n","            'upper_stl_path': upper_stl if upper_stl.exists() else None,\n","            'lower_stl_path': lower_stl if lower_stl.exists() else None,\n","            'data_type': data_type\n","        }\n","\n","        # Add ground truth paths\n","        if data_type == 'labeled':\n","            # Original labels\n","            gt_dir = labels_dir / case_id\n","        else:\n","            # Pseudo-labels\n","            gt_dir = labels_dir / case_id\n","\n","        if gt_dir.exists():\n","            upper_gt = gt_dir / \"upper_gt.npy\"\n","            lower_gt = gt_dir / \"lower_gt.npy\"\n","\n","            if upper_gt.exists():\n","                sample['upper_gt_path'] = upper_gt\n","            if lower_gt.exists():\n","                sample['lower_gt_path'] = lower_gt\n","\n","        return sample\n","\n","    def extract_cbct_points(self, cbct_path, threshold=800, max_points=50000):\n","        \"\"\"Same as before\"\"\"\n","        try:\n","            if not cbct_path.exists():\n","                return np.zeros((1000, 3), dtype=np.float32)\n","\n","            cbct_img = nib.load(str(cbct_path))\n","            cbct_data = cbct_img.get_fdata()\n","            points_voxel = np.argwhere(cbct_data > threshold)\n","\n","            if len(points_voxel) == 0:\n","                return np.zeros((1000, 3), dtype=np.float32)\n","\n","            points_h = np.hstack([points_voxel[:, [2, 1, 0]], np.ones((points_voxel.shape[0], 1))])\n","            points_world = (cbct_img.affine @ points_h.T).T[:, :3]\n","\n","            if len(points_world) > max_points:\n","                indices = np.random.choice(len(points_world), max_points, replace=False)\n","                points_world = points_world[indices]\n","\n","            return points_world.astype(np.float32)\n","\n","        except Exception as e:\n","            print(f\"Error extracting CBCT: {e}\")\n","            return np.zeros((1000, 3), dtype=np.float32)\n","\n","    def extract_stl_points(self, stl_path, max_points=50000):\n","        \"\"\"Same as before\"\"\"\n","        try:\n","            if stl_path is None or not stl_path.exists():\n","                return np.zeros((1000, 3), dtype=np.float32)\n","\n","            mesh = o3d.io.read_triangle_mesh(str(stl_path))\n","\n","            if len(mesh.triangles) == 0 or len(mesh.vertices) == 0:\n","                return np.zeros((1000, 3), dtype=np.float32)\n","\n","            points = np.asarray(mesh.vertices)\n","\n","            if len(points) > max_points:\n","                indices = np.random.choice(len(points), max_points, replace=False)\n","                points = points[indices]\n","\n","            return points.astype(np.float32)\n","\n","        except Exception as e:\n","            return np.zeros((1000, 3), dtype=np.float32)\n","\n","    def apply_pre_training_icp(self, stl_points, cbct_points, transform):\n","        \"\"\"Apply ICP refinement before training (optional)\"\"\"\n","        if not self.apply_icp_before_training:\n","            return transform\n","\n","        try:\n","            # Simple ICP refinement\n","            stl_h = np.hstack([stl_points, np.ones((len(stl_points), 1))])\n","            transformed_stl = (transform @ stl_h.T).T[:, :3]\n","\n","            # Subsample for speed\n","            if len(transformed_stl) > 1000:\n","                idx = np.random.choice(len(transformed_stl), 1000, replace=False)\n","                transformed_stl = transformed_stl[idx]\n","                stl_subset = stl_points[idx]\n","            else:\n","                stl_subset = stl_points\n","\n","            if len(cbct_points) > 1000:\n","                idx = np.random.choice(len(cbct_points), 1000, replace=False)\n","                cbct_subset = cbct_points[idx]\n","            else:\n","                cbct_subset = cbct_points\n","\n","            # Quick ICP iterations\n","            current_transform = np.eye(4)\n","            current_source = transformed_stl.copy()\n","\n","            for i in range(5):  # Just 5 iterations\n","                # Find correspondences\n","                from scipy.spatial.distance import cdist\n","                distances = cdist(current_source, cbct_subset)\n","                nearest_idx = np.argmin(distances, axis=1)\n","                min_distances = np.min(distances, axis=1)\n","\n","                # Filter outliers\n","                threshold = np.percentile(min_distances, 70)\n","                valid_mask = min_distances <= threshold\n","\n","                if np.sum(valid_mask) < 20:\n","                    break\n","\n","                valid_source = current_source[valid_mask]\n","                valid_target = cbct_subset[nearest_idx[valid_mask]]\n","\n","                # Compute adjustment\n","                src_centroid = np.mean(valid_source, axis=0)\n","                tgt_centroid = np.mean(valid_target, axis=0)\n","                translation = tgt_centroid - src_centroid\n","\n","                # Apply adjustment\n","                current_source += translation\n","                adjustment = np.eye(4)\n","                adjustment[:3, 3] = translation\n","                current_transform = adjustment @ current_transform\n","\n","            # Combine transforms\n","            refined_transform = current_transform @ transform\n","            return refined_transform\n","\n","        except:\n","            return transform\n","\n","    def __getitem__(self, idx):\n","        \"\"\"Updated to handle both labeled and pseudo-labeled data\"\"\"\n","        sample = self.samples[idx]\n","\n","        # Extract points (same as before)\n","        cbct_points = self.extract_cbct_points(sample['cbct_path'], threshold=800, max_points=50000)\n","        upper_points = self.extract_stl_points(sample['upper_stl_path'], max_points=50000)\n","        lower_points = self.extract_stl_points(sample['lower_stl_path'], max_points=50000)\n","\n","        # Combine STL points\n","        if len(upper_points) > 0 and len(lower_points) > 0:\n","            stl_points = np.vstack([upper_points, lower_points])\n","        elif len(upper_points) > 0:\n","            stl_points = upper_points\n","        elif len(lower_points) > 0:\n","            stl_points = lower_points\n","        else:\n","            stl_points = np.zeros((1000, 3), dtype=np.float32)\n","\n","        # Apply ground truth transformation\n","        target_points = stl_points.copy()\n","        gt_transform = np.eye(4, dtype=np.float32)\n","\n","        # Load ground truth\n","        upper_gt_exists = ('upper_gt_path' in sample and\n","                          sample['upper_gt_path'] is not None and\n","                          sample['upper_gt_path'].exists())\n","\n","        if upper_gt_exists and len(upper_points) > 0:\n","            try:\n","                upper_gt = np.load(sample['upper_gt_path'])\n","\n","                # Apply pre-training ICP if enabled and this is pseudo-labeled data\n","                if sample['data_type'] == 'pseudo':\n","                    upper_gt = self.apply_pre_training_icp(upper_points, cbct_points, upper_gt)\n","\n","                upper_h = np.hstack([upper_points, np.ones((len(upper_points), 1))])\n","                upper_transformed = (upper_gt @ upper_h.T).T[:, :3]\n","\n","                lower_gt_exists = ('lower_gt_path' in sample and\n","                                  sample['lower_gt_path'] is not None and\n","                                  sample['lower_gt_path'].exists())\n","\n","                if lower_gt_exists and len(lower_points) > 0:\n","                    try:\n","                        lower_gt = np.load(sample['lower_gt_path'])\n","\n","                        # Apply pre-training ICP if enabled and this is pseudo-labeled data\n","                        if sample['data_type'] == 'pseudo':\n","                            lower_gt = self.apply_pre_training_icp(lower_points, cbct_points, lower_gt)\n","\n","                        lower_h = np.hstack([lower_points, np.ones((len(lower_points), 1))])\n","                        lower_transformed = (lower_gt @ lower_h.T).T[:, :3]\n","                        target_points = np.vstack([upper_transformed, lower_transformed])\n","                    except:\n","                        target_points = upper_transformed\n","                else:\n","                    target_points = upper_transformed\n","\n","                gt_transform = upper_gt\n","\n","            except Exception as e:\n","                print(f\"Error loading GT for {sample['case_id']}: {e}\")\n","\n","        # Normalization (same as before)\n","        if len(cbct_points) > 0 and len(stl_points) > 0:\n","            all_points = np.vstack([cbct_points, stl_points])\n","            center = np.mean(all_points, axis=0)\n","            scale = np.max(np.linalg.norm(all_points - center, axis=1))\n","\n","            if scale > 0:\n","                cbct_norm = (cbct_points - center) / scale\n","                stl_norm = (stl_points - center) / scale\n","                target_norm = (target_points - center) / scale\n","            else:\n","                cbct_norm = cbct_points - center\n","                stl_norm = stl_points - center\n","                target_norm = target_points - center\n","            norm_center = torch.from_numpy(center).float()\n","            norm_scale = torch.tensor(scale).float()\n","        else:\n","            cbct_norm = cbct_points\n","            stl_norm = stl_points\n","            target_norm = target_points\n","            norm_center = torch.zeros(3).float()\n","            norm_scale = torch.tensor(1.0).float()\n","\n","        # Data augmentation (same as before)\n","        if self.transform is not None and self.mode == 'train':\n","            stl_norm, aug_transform = self.transform(stl_norm)\n","            gt_transform = aug_transform @ gt_transform\n","\n","        # Sample points (same as before)\n","        cbct_sampled = self.sample_points(cbct_norm, self.n_points)\n","        stl_sampled = self.sample_points(stl_norm, self.n_points)\n","        target_sampled = self.sample_points(target_norm, self.n_points)\n","\n","        return {\n","            'cbct': torch.from_numpy(cbct_sampled).float(),\n","            'stl': torch.from_numpy(stl_sampled).float(),\n","            'target': torch.from_numpy(target_sampled).float(),\n","            'gt_transform': torch.from_numpy(gt_transform).float(),\n","            'norm_center': norm_center,\n","            'norm_scale': norm_scale,\n","            'case_id': sample['case_id'],\n","            'data_type': sample['data_type']  # Add this to track data source\n","        }\n","\n","    def sample_points(self, points, n_target):\n","        \"\"\"Same as before\"\"\"\n","        if len(points) == 0:\n","            return np.zeros((n_target, 3), dtype=np.float32)\n","\n","        if len(points) >= n_target:\n","            indices = np.random.choice(len(points), n_target, replace=False)\n","            return points[indices]\n","        else:\n","            indices = np.random.choice(len(points), n_target, replace=True)\n","            return points[indices]\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","\n","# ============================================================================\n","# MAIN EXECUTION\n","# ============================================================================\n","def main_semi_supervised():\n","    \"\"\"Updated main function for semi-supervised training\"\"\"\n","\n","    # Updated configuration for semi-supervised learning\n","    config = {\n","        'data_root': \"/content/drive/MyDrive/Papers/STS_2025/VERSION2/DATASET\",\n","        'pseudo_labels_dir': \"/content/drive/MyDrive/Papers/STS_2025/VERSION2/PSEUDO_LABELS_SIMPLE\",\n","        'save_dir': \"/content/drive/MyDrive/Papers/STS_2025/VERSION2/RESULTS_SEMI_SUPERVISED\",\n","        'batch_size': 4,\n","        'num_epochs': 15,  # Reduced since we have more data now\n","        'learning_rate': 1e-4,  # Slightly lower LR for stability\n","        'n_points': 1024,\n","        'feature_dim': 1024,\n","        'num_iterations': 5,  # INCREASED for better alignment\n","        'apply_icp_before_training': True  # Set to True if pseudo-label test shows it helps\n","    }\n","\n","    # Setup\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    print(f\"Using device: {device}\")\n","\n","    # Create semi-supervised datasets\n","    print(\"Creating semi-supervised datasets...\")\n","    train_dataset = STSRSemiSupervisedDataset(\n","        root_dir=config['data_root'],\n","        pseudo_labels_dir=config['pseudo_labels_dir'],\n","        n_points=config['n_points'],\n","        mode='train',\n","        augment=True,\n","        apply_icp_before_training=config['apply_icp_before_training']\n","    )\n","\n","    # Validation dataset (unchanged - only real labels)\n","    val_dataset = STSRDataset(\n","        root_dir=config['data_root'],\n","        n_points=config['n_points'],\n","        mode='val',\n","        augment=False\n","    )\n","\n","    # Create data loaders\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=config['batch_size'],\n","        shuffle=True,\n","        num_workers=2,\n","        pin_memory=True,\n","        drop_last=True\n","    )\n","\n","    val_loader = DataLoader(\n","        val_dataset,\n","        batch_size=config['batch_size'],\n","        shuffle=False,\n","        num_workers=2,\n","        pin_memory=True,\n","        drop_last=True\n","    )\n","\n","    print(f\"Dataset sizes - Train: {len(train_dataset)}, Val: {len(val_dataset)}\")\n","\n","    # Create improved model with more iterations\n","    print(\"Creating improved model...\")\n","    model = STSRModel(\n","        feature_dim=config['feature_dim'],\n","        num_iterations=config['num_iterations']\n","    ).to(device)\n","\n","    # OPTIONALLY: Load pre-trained weights from previous training\n","    pretrained_path = \"/content/drive/MyDrive/Papers/STS_2025/VERSION2/RESULTS_OFFICIAL/best_model_state_dict.pth\"\n","    if Path(pretrained_path).exists():\n","        try:\n","            print(\"Loading pre-trained weights...\")\n","            model.load_state_dict(torch.load(pretrained_path, map_location=device))\n","            print(\"✓ Pre-trained weights loaded successfully\")\n","        except Exception as e:\n","            print(f\"Warning: Could not load pre-trained weights: {e}\")\n","            print(\"Training from scratch...\")\n","\n","    # Count parameters\n","    total_params = sum(p.numel() for p in model.parameters())\n","    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    print(f\"Model parameters - Total: {total_params:,}, Trainable: {trainable_params:,}\")\n","\n","    # Create trainer\n","    trainer = STSRTrainer(model, device, config['save_dir'])\n","\n","    # Train model with semi-supervised data\n","    print(\"\\nStarting semi-supervised training...\")\n","    history = trainer.train(\n","        train_loader,\n","        val_loader,\n","        config['num_epochs'],\n","        config['learning_rate']\n","    )\n","\n","    # Save training history\n","    with open(trainer.save_dir / 'semi_supervised_history.json', 'w') as f:\n","        json.dump({k: [float(x) for x in v] for k, v in history.items()}, f, indent=2)\n","\n","    # Load best model for inference\n","    print(\"\\nLoading best model for inference...\")\n","    try:\n","        checkpoint = torch.load(trainer.save_dir / 'best_model_state_dict.pth')\n","        model.load_state_dict(checkpoint)\n","        print(\"✓ Model loaded successfully\")\n","    except Exception as e:\n","        print(f\"Warning: Could not load best model: {e}\")\n","        print(\"Using final model instead...\")\n","        checkpoint = torch.load(trainer.save_dir / 'final_model_state_dict.pth')\n","        model.load_state_dict(checkpoint)\n","\n","    # Final evaluation\n","    print(\"\\nFinal evaluation on validation set:\")\n","    final_loss, final_metrics = trainer.validate_epoch(val_loader)\n","\n","    print(f\"\\nSemi-Supervised Training Results:\")\n","    print(f\"Validation Loss: {final_loss:.6f}\")\n","    print(f\"RMSE: {final_metrics['rmse']:.4f} mm\")\n","    print(f\"Translation Error: {final_metrics['translation_error']:.4f} mm\")\n","    print(f\"Rotation Error: {final_metrics['rotation_error_degrees']:.2f} degrees\")\n","    print(f\"Surface Dice: {final_metrics['surface_dice']:.4f}\")\n","    print(f\"Chamfer Distance: {final_metrics['chamfer_distance']:.4f}\")\n","\n","    # Save final results\n","    final_results = {\n","        'final_loss': final_loss,\n","        'final_metrics': final_metrics,\n","        'config': config,\n","        'model_parameters': {\n","            'total': total_params,\n","            'trainable': trainable_params\n","        }\n","    }\n","\n","    with open(trainer.save_dir / 'final_results.json', 'w') as f:\n","        json.dump(final_results, f, indent=2, default=str)\n","\n","    print(f\"\\nAll results saved to: {trainer.save_dir}\")\n","    print(\"Semi-supervised training completed successfully!\")\n","\n","    return model, history, final_metrics\n","\n","if __name__ == \"__main__\":\n","    \"\"\"\n","    Complete Semi-Supervised Training Pipeline\n","    \"\"\"\n","\n","    print(\"=\"*80)\n","    print(\"STSR 2025 SEMI-SUPERVISED TRAINING PIPELINE\")\n","    print(\"=\"*80)\n","\n","    # Step 1: Verify pseudo-label quality (optional - you already did this)\n","    print(\"\\nStep 1: Pseudo-label Quality Check\")\n","    print(\"-\" * 40)\n","\n","    pseudo_labels_dir = \"/content/drive/MyDrive/Papers/STS_2025/VERSION2/PSEUDO_LABELS_SIMPLE\"\n","    data_root = \"/content/drive/MyDrive/Papers/STS_2025/VERSION2/DATASET\"\n","\n","    # Quick verification that directories exist\n","    if not Path(pseudo_labels_dir).exists():\n","        print(f\"ERROR: Pseudo-labels directory not found: {pseudo_labels_dir}\")\n","        exit()\n","    if not Path(data_root).exists():\n","        print(f\"ERROR: Data root directory not found: {data_root}\")\n","        exit()\n","\n","    print(f\"✓ Pseudo-labels found: {len(list(Path(pseudo_labels_dir).iterdir()))} cases\")\n","    print(\"✓ Pseudo-labels already tested and approved for training\")\n","\n","    # Step 2: Start semi-supervised training\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"Step 2: STARTING SEMI-SUPERVISED TRAINING\")\n","    print(\"=\"*80)\n","\n","    try:\n","        # Execute main training function\n","        model, history, final_metrics = main_semi_supervised()\n","\n","        print(\"\\n\" + \"=\"*80)\n","        print(\"TRAINING COMPLETED SUCCESSFULLY!\")\n","        print(\"=\"*80)\n","\n","        # Display comparison with previous results\n","        print(\"\\nComparison with Previous Training:\")\n","        print(\"-\" * 40)\n","\n","        # Previous results (your baseline)\n","        prev_translation = 55.96\n","        prev_rotation = 134.07\n","        prev_surface_dice = 0.8891\n","        prev_chamfer = 1.2895\n","\n","        # Current results\n","        curr_translation = final_metrics.get('translation_error', 0)\n","        curr_rotation = final_metrics.get('rotation_error_degrees', 0)\n","        curr_surface_dice = final_metrics.get('surface_dice', 0)\n","        curr_chamfer = final_metrics.get('chamfer_distance', 0)\n","\n","        # Calculate improvements\n","        trans_improvement = prev_translation - curr_translation\n","        rot_improvement = prev_rotation - curr_rotation\n","        dice_improvement = curr_surface_dice - prev_surface_dice\n","        chamfer_improvement = prev_chamfer - curr_chamfer\n","\n","        print(f\"Translation Error:    {prev_translation:.2f}mm → {curr_translation:.2f}mm \"\n","              f\"({'↓' if trans_improvement > 0 else '↑'}{abs(trans_improvement):.2f}mm)\")\n","        print(f\"Rotation Error:       {prev_rotation:.2f}° → {curr_rotation:.2f}° \"\n","              f\"({'↓' if rot_improvement > 0 else '↑'}{abs(rot_improvement):.2f}°)\")\n","        print(f\"Surface Dice:         {prev_surface_dice:.4f} → {curr_surface_dice:.4f} \"\n","              f\"({'↑' if dice_improvement > 0 else '↓'}{abs(dice_improvement):.4f})\")\n","        print(f\"Chamfer Distance:     {prev_chamfer:.4f} → {curr_chamfer:.4f} \"\n","              f\"({'↓' if chamfer_improvement > 0 else '↑'}{abs(chamfer_improvement):.4f})\")\n","\n","        # Overall assessment\n","        improvements = sum([\n","            trans_improvement > 2,    # Translation improved by >2mm\n","            rot_improvement > 10,     # Rotation improved by >10°\n","            dice_improvement > 0.01,  # Dice improved by >0.01\n","            chamfer_improvement > 0.1 # Chamfer improved by >0.1\n","        ])\n","\n","        print(f\"\\nOverall Assessment: {improvements}/4 metrics improved\")\n","\n","        if improvements >= 3:\n","            print(\"🎉 EXCELLENT! Semi-supervised training was very successful!\")\n","        elif improvements >= 2:\n","            print(\"✅ GOOD! Semi-supervised training showed clear benefits!\")\n","        elif improvements >= 1:\n","            print(\"✓ FAIR! Some improvement from semi-supervised training!\")\n","        else:\n","            print(\"⚠ Mixed results. Consider tuning hyperparameters.\")\n","\n","        # Model info\n","        print(f\"\\nModel Architecture:\")\n","        print(f\"- Training Data: ~353 samples (65 labeled + 288 pseudo-labeled)\")\n","        print(f\"- PointNetLK Iterations: 10 (increased from 5)\")\n","        print(f\"- Learning Rate: 3e-4 (reduced for stability)\")\n","        print(f\"- Training Epochs: 30\")\n","\n","        # Save comparison results\n","        save_dir = Path(\"/content/drive/MyDrive/Papers/STS_2025/VERSION2/RESULTS_SEMI_SUPERVISED\")\n","        comparison = {\n","            'previous_results': {\n","                'translation_error': prev_translation,\n","                'rotation_error_degrees': prev_rotation,\n","                'surface_dice': prev_surface_dice,\n","                'chamfer_distance': prev_chamfer\n","            },\n","            'current_results': final_metrics,\n","            'improvements': {\n","                'translation_improvement_mm': trans_improvement,\n","                'rotation_improvement_deg': rot_improvement,\n","                'surface_dice_improvement': dice_improvement,\n","                'chamfer_improvement': chamfer_improvement,\n","                'metrics_improved': improvements,\n","                'overall_success': improvements >= 2\n","            }\n","        }\n","\n","        with open(save_dir / 'training_comparison.json', 'w') as f:\n","            json.dump(comparison, f, indent=2, default=str)\n","\n","        print(f\"\\n✓ Detailed comparison saved to: {save_dir / 'training_comparison.json'}\")\n","        print(f\"✓ All training results saved to: {save_dir}\")\n","\n","    except Exception as e:\n","        print(f\"\\n❌ Training failed with error: {e}\")\n","        print(\"\\nTroubleshooting suggestions:\")\n","        print(\"1. Check that all required functions are imported\")\n","        print(\"2. Verify GPU memory is available\")\n","        print(\"3. Ensure data paths are correct\")\n","        print(\"4. Check that pseudo-labels are properly formatted\")\n","\n","        import traceback\n","        traceback.print_exc()\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"SEMI-SUPERVISED TRAINING PIPELINE COMPLETE\")\n","    print(\"=\"*80)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nXdjIxJvio2l","outputId":"08c5e9ce-4eab-493c-f727-8bd2e5cbe155"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["================================================================================\n","STSR 2025 SEMI-SUPERVISED TRAINING PIPELINE\n","================================================================================\n","\n","Step 1: Pseudo-label Quality Check\n","----------------------------------------\n","✓ Pseudo-labels found: 289 cases\n","✓ Pseudo-labels already tested and approved for training\n","\n","================================================================================\n","Step 2: STARTING SEMI-SUPERVISED TRAINING\n","================================================================================\n","Using device: cuda\n","Creating semi-supervised datasets...\n","Loaded 353 samples for train\n","  - Labeled: 65\n","  - Pseudo-labeled: 288\n","Loaded 15 samples for val\n","Dataset sizes - Train: 353, Val: 15\n","Creating improved model...\n","Loading pre-trained weights...\n","✓ Pre-trained weights loaded successfully\n","Model parameters - Total: 813,586, Trainable: 813,586\n","\n","Starting semi-supervised training...\n","\n","Epoch 1/15\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 88/88 [51:53<00:00, 35.38s/it, Loss=6.9728, Chamfer=4.4671, Transform=2.5057]\n","Validation: 100%|██████████| 3/3 [01:23<00:00, 27.78s/it, Loss=2.7624, Chamfer=1.5327, Transform=1.2297]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 5.630620 | Val Loss: 2.676543\n","RMSE: 0.6839 | Translation: 55.8535mm | Rotation: 147.58°\n","Surface Dice: 0.8246 | Chamfer: 1.5035\n","✓ Best model saved: 2.676543\n","\n","Epoch 2/15\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 88/88 [52:37<00:00, 35.88s/it, Loss=5.1916, Chamfer=3.2496, Transform=1.9420]\n","Validation: 100%|██████████| 3/3 [01:27<00:00, 29.04s/it, Loss=4.3394, Chamfer=2.4169, Transform=1.9225]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 5.020841 | Val Loss: 4.926700\n","RMSE: 1.0367 | Translation: 56.9017mm | Rotation: 140.25°\n","Surface Dice: 0.1710 | Chamfer: 2.8258\n","No improvement for 1/10 epochs\n","\n","Epoch 3/15\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 88/88 [53:01<00:00, 36.16s/it, Loss=4.6313, Chamfer=2.8612, Transform=1.7701]\n","Validation: 100%|██████████| 3/3 [01:27<00:00, 29.08s/it, Loss=3.7667, Chamfer=2.0805, Transform=1.6862]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 4.561512 | Val Loss: 4.292101\n","RMSE: 0.9306 | Translation: 56.4547mm | Rotation: 140.14°\n","Surface Dice: 0.4633 | Chamfer: 2.4045\n","No improvement for 2/10 epochs\n","\n","Epoch 4/15\n"]},{"output_type":"stream","name":"stderr","text":["Training:  38%|███▊      | 33/88 [20:42<35:57, 39.23s/it, Loss=3.7905, Chamfer=2.2353, Transform=1.5551]"]}]}]}
